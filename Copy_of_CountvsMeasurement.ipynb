{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of CountvsMeasurement.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "562844cb36be4778a96d61115a9593ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4360d32278984bcfaed40480e87b7aac",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f4891b8a033418b81f672e54b1e5ad8",
              "IPY_MODEL_f3979788ca9a4946acd1adea8d2c84a2"
            ]
          }
        },
        "4360d32278984bcfaed40480e87b7aac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f4891b8a033418b81f672e54b1e5ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1d59a586a252454ebc8c8bbcbef7c63a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08f99da93fa647d7a2e93359b8602932"
          }
        },
        "f3979788ca9a4946acd1adea8d2c84a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0371dcdc01e84a9eb6b8a29db45965cf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 375kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_402d2be7f27e46be8ecee6cdbb655fa2"
          }
        },
        "1d59a586a252454ebc8c8bbcbef7c63a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08f99da93fa647d7a2e93359b8602932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0371dcdc01e84a9eb6b8a29db45965cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "402d2be7f27e46be8ecee6cdbb655fa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IH9efjEdM1w",
        "outputId": "59bad03b-783b-48f8-8975-8741a3aef21a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 18.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 22.8MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 38.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=1140765b6138c252575c97e3787be9ef829ca9c3fd0bbbce78c83e4591e2dffb\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv5XpXpcHKRo",
        "outputId": "ba671312-e723-4917-e9b0-24034caf7902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForPreTraining\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import ast \n",
        "import numpy as np\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLcVKcyeDIF3",
        "outputId": "74006ce9-4242-4863-941d-e6767ff4839f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qcFkZ0EDfYS",
        "outputId": "72f20af0-898c-4424-ddc7-2d1bb193ca11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/MeasEval-main/data/train/train/text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MeasEval-main/data/train/train/text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkemwFQIKc9n"
      },
      "source": [
        "files=os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnUNLHH4kh-0",
        "outputId": "3febdf6f-c53a-4950-ba98-74c9d82c4fa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/MeasEval-main/data/train/dev/text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MeasEval-main/data/train/dev/text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdDn6wJzkhu-"
      },
      "source": [
        "files_val=os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1KtrcEIKIv-",
        "outputId": "5e1c1eba-9203-4c82-8fa5-c1fcc735cbd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/MeasEval-main/data/train/train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MeasEval-main/data/train/train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XojnfEPjsj8g",
        "outputId": "307596ab-5cf6-4886-c4c3-5a4ddaae8630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "562844cb36be4778a96d61115a9593ef",
            "4360d32278984bcfaed40480e87b7aac",
            "4f4891b8a033418b81f672e54b1e5ad8",
            "f3979788ca9a4946acd1adea8d2c84a2",
            "1d59a586a252454ebc8c8bbcbef7c63a",
            "08f99da93fa647d7a2e93359b8602932",
            "0371dcdc01e84a9eb6b8a29db45965cf",
            "402d2be7f27e46be8ecee6cdbb655fa2"
          ]
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "562844cb36be4778a96d61115a9593ef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjHjWw_HsrCA"
      },
      "source": [
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "\n",
        "    \n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "    # print(len(tokenized_sentence))\n",
        "    # print(len(labels))\n",
        "    return tokenized_sentence, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdvWWPFHght"
      },
      "source": [
        "l=0\n",
        "NERdata=[]\n",
        "for i in files:\n",
        "  \n",
        "  pathtxt=os.path.join('text',i)\n",
        "  \n",
        "  with open(pathtxt, 'r') as f:\n",
        "    text=f.read()\n",
        "  pathtsv=os.path.join('tsv',i[:-3]+'tsv')\n",
        "  if(not(os.path.exists(pathtsv))):\n",
        "    continue\n",
        "  filetsv=pd.read_csv(pathtsv,sep = '\\t')\n",
        "  entity=filetsv[['annotType','startOffset','endOffset','text','other']]\n",
        "  entity=entity[entity['annotType']=='Quantity']\n",
        "  \n",
        "  entity = entity.to_numpy().tolist()\n",
        "\n",
        "  ent=0\n",
        "  offset=0\n",
        "  sent_text = nltk.sent_tokenize(text)\n",
        "  \n",
        "  for j in sent_text:\n",
        "    row=[]\n",
        "    row.append(i[:-4])\n",
        "    \n",
        "    \n",
        "    ent_sen=[]\n",
        "    ret = [(m.group(0), m.start(), m.end() - 1) for m in re.finditer(r'\\S+', j)]\n",
        "    start=[]\n",
        "    \n",
        "    for word in ret:\n",
        "      types=[]\n",
        "      # other=[]\n",
        "      for ent_doc in entity:\n",
        "        \n",
        "        if(offset+word[1]>=ent_doc[1] and offset+word[2]<=ent_doc[2]):\n",
        "          dictio={}\n",
        "          if(not pd.isnull(ent_doc[4])):\n",
        "            dictio=ast.literal_eval(ent_doc[4])\n",
        "\n",
        "          \n",
        "          if('mods' in dictio):\n",
        "            info=dictio['mods']\n",
        "            \n",
        "            if('IsCount' in info):\n",
        "              types.append(\"Count\")\n",
        "              \n",
        "            else:\n",
        "              types.append(\"Measurement\")\n",
        "          else:\n",
        "            types.append(\"Measurement\")\n",
        "\n",
        "\n",
        "        # print(word,types,dictio)\n",
        "      \n",
        "      ent_sen.append(types)     \n",
        "    \n",
        "    # print(ent_sen)\n",
        "    sen,label=tokenize_and_preserve_labels(j.split(' '),ent_sen,tokenizer)\n",
        "    label.insert(0,[])\n",
        "    label.append([])\n",
        "    offset+=(1+len(j))\n",
        "    # print(j)\n",
        "    # print(label)\n",
        "    row.append(j)\n",
        "    row.append(label)\n",
        "    \n",
        "    NERdata.append(row)\n",
        "    \n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbWjqjF4J3ZZ"
      },
      "source": [
        "NERdf=pd.DataFrame (NERdata, columns = ['Id','Text','Entity'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hW-wTFpk19j",
        "outputId": "07b996a7-8601-4003-eea6-3362f8c4d620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/MeasEval-main/data/train/dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MeasEval-main/data/train/dev\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuK7hEHNk1tk"
      },
      "source": [
        "l=0\n",
        "NERdata=[]\n",
        "for i in files_val:\n",
        "  \n",
        "  pathtxt=os.path.join('text',i)\n",
        "  \n",
        "  with open(pathtxt, 'r') as f:\n",
        "    text=f.read()\n",
        "  pathtsv=os.path.join('tsv',i[:-3]+'tsv')\n",
        "  if(not(os.path.exists(pathtsv))):\n",
        "    continue\n",
        "  filetsv=pd.read_csv(pathtsv,sep = '\\t')\n",
        "  entity=filetsv[['annotType','startOffset','endOffset','text','other']]\n",
        "  entity=entity[entity['annotType']=='Quantity']\n",
        "  \n",
        "  entity = entity.to_numpy().tolist()\n",
        "\n",
        "  ent=0\n",
        "  offset=0\n",
        "  sent_text = nltk.sent_tokenize(text)\n",
        "  \n",
        "  for j in sent_text:\n",
        "    row=[]\n",
        "    row.append(i[:-4])\n",
        "    \n",
        "    \n",
        "    ent_sen=[]\n",
        "    ret = [(m.group(0), m.start(), m.end() - 1) for m in re.finditer(r'\\S+', j)]\n",
        "    start=[]\n",
        "    \n",
        "    for word in ret:\n",
        "      types=[]\n",
        "      # other=[]\n",
        "      for ent_doc in entity:\n",
        "        \n",
        "        if(offset+word[1]>=ent_doc[1] and offset+word[2]<=ent_doc[2]):\n",
        "          dictio={}\n",
        "          if(not pd.isnull(ent_doc[4])):\n",
        "            dictio=ast.literal_eval(ent_doc[4])\n",
        "\n",
        "          \n",
        "          if('mods' in dictio):\n",
        "            info=dictio['mods']\n",
        "            \n",
        "            if('IsCount' in info):\n",
        "              types.append(\"Count\")\n",
        "              \n",
        "            else:\n",
        "              types.append(\"Measurement\")\n",
        "          else:\n",
        "            types.append(\"Measurement\")\n",
        "\n",
        "\n",
        "        # print(word,types,dictio)\n",
        "      \n",
        "      ent_sen.append(types)     \n",
        "    \n",
        "    # print(ent_sen)\n",
        "    sen,label=tokenize_and_preserve_labels(j.split(' '),ent_sen,tokenizer)\n",
        "    label.insert(0,[])\n",
        "    label.append([])\n",
        "    offset+=(1+len(j))\n",
        "    # print(j)\n",
        "    # print(label)\n",
        "    row.append(j)\n",
        "    row.append(label)\n",
        "    \n",
        "    NERdata.append(row)\n",
        "    \n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nezcb5E-lTmg"
      },
      "source": [
        "NERdf_val=pd.DataFrame (NERdata, columns = ['Id','Text','Entity'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0-ojS-opCM3"
      },
      "source": [
        "NERdf_val[\"len\"] = NERdf_val[\"Entity\"].apply(lambda x: len_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyYcSHgapJdl",
        "outputId": "c3515c0e-b413-4dcb-fdc7-5bbbf6395d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(NERdf_val[NERdf_val[\"len\"] != 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                          Id  ... len\n",
            "0      S0031405612000728-769  ...   1\n",
            "6     S0032063312003054-2501  ...   3\n",
            "8     S0032063312003054-2501  ...   1\n",
            "20    S0025322712001600-2230  ...   1\n",
            "34     S0032063312002437-627  ...   3\n",
            "71    S030881461301604X-1002  ...   1\n",
            "143  S0022000014000026-18167  ...   1\n",
            "\n",
            "[7 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nph9XcbiYGTw"
      },
      "source": [
        "def len_text(x):\n",
        "  sum = 0\n",
        "  for en in x:\n",
        "    #print(en)\n",
        "    if en==['Count']:\n",
        "      sum += len(en)\n",
        "  return sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrYAOg6pYG-Z"
      },
      "source": [
        "NERdf[\"len\"] = NERdf[\"Entity\"].apply(lambda x: len_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWDZxkFdYGtR"
      },
      "source": [
        "NERdf_nz = NERdf[NERdf[\"len\"] != 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFfvWOzAYGGc"
      },
      "source": [
        "#NERdf_z = NERdf[NERdf[\"len\"] == 0].sample(400)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7BsCyaNaPWd"
      },
      "source": [
        "#NERdf = pd.concat([NERdf_nz, NERdf_z])\n",
        "NERdf = NERdf_nz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAJmeJ-SaPH8",
        "outputId": "703fb77d-5e22-457a-9b7c-7f1590e79f77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "NERdf.sample(frac=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Text</th>\n",
              "      <th>Entity</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>S0019103511004994-1399</td>\n",
              "      <td>Enceladus, one out of currently 62 satellites ...</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [], [], [Coun...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>S0006322312001096-1177</td>\n",
              "      <td>The target population was all London-based off...</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>S016412121300188X-5066</td>\n",
              "      <td>The coherent cluster existence study is extend...</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>S0012821X12004384-1284</td>\n",
              "      <td>Carbon isotope analysis was carried out on 289...</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [Count], [], ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>715</th>\n",
              "      <td>S016412121300188X-4545</td>\n",
              "      <td>Table 4 shows the statistics for the five larg...</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [Count], [], ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>S1750583613004192-714</td>\n",
              "      <td>The nine plume layers are well defined aeriall...</td>\n",
              "      <td>[[], [], [Count], [], [], [], [], [], [], [], ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>S016412121300188X-4545</td>\n",
              "      <td>These five clusters can be readily identified ...</td>\n",
              "      <td>[[], [], [Count], [], [], [], [], [], [], [], ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1020</th>\n",
              "      <td>S0012821X12004384-1405</td>\n",
              "      <td>Samples with fewer than 20 specimens were also...</td>\n",
              "      <td>[[], [], [], [], [], [Count], [], [], [], [], ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>680</th>\n",
              "      <td>S0921818113002245-1571</td>\n",
              "      <td>Five cores for paleomagnetic measurements were...</td>\n",
              "      <td>[[], [Count], [], [], [], [], [], [], [], [], ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627</th>\n",
              "      <td>S016412121300188X-5038</td>\n",
              "      <td>As an answer to RQ7, this study finds that unl...</td>\n",
              "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>73 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Id  ... len\n",
              "445   S0019103511004994-1399  ...   2\n",
              "723   S0006322312001096-1177  ...   1\n",
              "862   S016412121300188X-5066  ...   1\n",
              "158   S0012821X12004384-1284  ...   1\n",
              "715   S016412121300188X-4545  ...   1\n",
              "...                      ...  ...  ..\n",
              "420    S1750583613004192-714  ...   1\n",
              "720   S016412121300188X-4545  ...   1\n",
              "1020  S0012821X12004384-1405  ...   1\n",
              "680   S0921818113002245-1571  ...   1\n",
              "627   S016412121300188X-5038  ...   1\n",
              "\n",
              "[73 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQ-Dx-ktYdCs",
        "outputId": "35412de8-5c3e-441a-9b4d-f1015609ffbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(NERdf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1370"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 319
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqdo-eglwE1W"
      },
      "source": [
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inldLu69ReBz"
      },
      "source": [
        "text=NERdf['Text'].tolist()\n",
        "textlabels=NERdf['Entity'].tolist()\n",
        "\n",
        "for i in range(len(textlabels)):\n",
        "  textlabels[i]=(textlabels[i] + 512 * [np.zeros(3)])[:512]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9Ub-hlMlg1n"
      },
      "source": [
        "text_val=NERdf_val['Text'].tolist()\n",
        "textlabels_val=NERdf_val['Entity'].tolist()\n",
        "\n",
        "for i in range(len(textlabels_val)):\n",
        "  textlabels_val[i]=(textlabels_val[i] + 512 * [np.zeros(3)])[:512]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jPHSjEZX-vP"
      },
      "source": [
        "def len_text(x):\n",
        "  sum = 0\n",
        "  for en in x:\n",
        "    sum += len(en)\n",
        "  return sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MB1yIa5X_X6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRJLcTWqX_4Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uh-0zLuX_Il"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmDeodXRX-Ng"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhcPsOW1kzna",
        "outputId": "75f1d0f1-b9cc-4eb9-f56a-c36eb8b6226d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(textlabels[0][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZZnpp1BwkIg"
      },
      "source": [
        "inputs = tokenizer(text,max_length = 512,padding='max_length',truncation=True, return_tensors=\"pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKahqI29lucZ"
      },
      "source": [
        "inputs_val = tokenizer(text_val,max_length = 512,padding='max_length',truncation=True, return_tensors=\"pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvgRLLO3Es4_"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOZig15Sy63R"
      },
      "source": [
        "train_seq = np.array(inputs['input_ids'])\n",
        "train_mask = np.array(inputs['attention_mask'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhVadcBrlz1V"
      },
      "source": [
        "val_seq = np.array(inputs_val['input_ids'])\n",
        "val_mask = np.array(inputs_val['attention_mask'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ymsDI5tuZDn"
      },
      "source": [
        "labels = {\"Count\":1, \"Measurement\": 2}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kII5xtUrqH_y"
      },
      "source": [
        "\n",
        "count=0\n",
        "\n",
        "\n",
        "onehot_labels = np.zeros((len(textlabels), len(textlabels[0]),1));\n",
        "for i in range(len(textlabels)):\n",
        "  for j in range(len(textlabels[0])):\n",
        "    if len(textlabels[i][j])!=0:\n",
        "      if (textlabels[i][j][0]==\"Count\"):\n",
        "        count+=1\n",
        "        onehot_labels[i][j][0] = 1\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96pxPDjPl6n7"
      },
      "source": [
        "\n",
        "count_val=0\n",
        "\n",
        "\n",
        "onehot_labels_val = np.zeros((len(textlabels_val), len(textlabels_val[0]),1));\n",
        "for i in range(len(textlabels_val)):\n",
        "  for j in range(len(textlabels_val[0])):\n",
        "    if len(textlabels_val[i][j])!=0:\n",
        "      if (textlabels_val[i][j][0]==\"Count\"):\n",
        "        count_val+=1\n",
        "        onehot_labels_val[i][j][0] = 1\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAMjGtIswhrf"
      },
      "source": [
        "val_y = onehot_labels_val\n",
        "train_y = onehot_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqgysWqu_5RX",
        "outputId": "96f1c9b2-ba21-4f89-9538-f3ee58649a79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(np.where(val_y[:,:,1]==1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([  2,   2,   4,   4,   4,   4,   4,   4,   4,   4,   7,   7,   7,\n",
            "         7,   8,   8,   8,   8,   9,   9,   9,   9,   9,   9,   9,   9,\n",
            "         9,   9,   9,   9,  11,  11,  11,  11,  11,  11,  11,  11,  14,\n",
            "        15,  15,  16,  16,  16,  19,  19,  19,  19,  19,  19,  21,  21,\n",
            "        21,  21,  28,  28,  28,  28,  28,  28,  30,  30,  30,  30,  31,\n",
            "        31,  31,  31,  31,  31,  31,  31,  31,  31,  31,  31,  31,  31,\n",
            "        31,  31,  31,  31,  31,  31,  31,  31,  31,  31,  31,  31,  36,\n",
            "        36,  38,  38,  38,  38,  38,  38,  38,  46,  46,  46,  52,  52,\n",
            "        52,  52,  52,  52,  52,  52,  52,  52,  54,  54,  54,  56,  56,\n",
            "        56,  56,  56,  66,  66,  66,  66,  68,  68,  68,  68,  68,  68,\n",
            "        68,  68,  68,  68,  69,  69,  69,  69,  69,  69,  69,  71,  71,\n",
            "        71,  71,  71,  72,  72,  72,  72,  72,  72,  76,  76,  77,  77,\n",
            "        77,  77,  77,  77,  77,  81,  81,  81,  81,  81,  81,  81,  84,\n",
            "        84,  84,  84,  84,  84,  88,  88,  88,  88,  88,  88,  88,  88,\n",
            "        88,  88,  88,  94,  94,  94,  95,  95,  95,  95,  95,  95,  95,\n",
            "        95,  95,  95, 100, 100, 110, 110, 110, 110, 110, 110, 110, 110,\n",
            "       111, 111, 111, 111, 111, 111, 111, 112, 112, 112, 114, 114, 114,\n",
            "       114, 114, 114, 114, 114, 114, 114, 114, 114, 120, 120, 120, 120,\n",
            "       120, 120, 120, 120, 120, 122, 122, 122, 122, 122, 122, 122, 122,\n",
            "       122, 122, 122, 122, 122, 127, 127, 127, 127, 127, 129, 129, 129,\n",
            "       129, 129, 129, 129, 133, 133, 133, 133, 134, 134, 134, 139, 139,\n",
            "       145, 145, 145, 145, 145, 145, 145, 145, 146, 146, 152, 152, 156,\n",
            "       156, 156, 156, 156, 158, 158, 158, 158, 158, 158, 158, 158, 158,\n",
            "       158, 158, 158, 158, 158, 158, 158, 158, 158, 167, 167, 167, 167,\n",
            "       167, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168, 168,\n",
            "       168, 168, 168, 171, 171, 171, 171, 171, 171, 175, 175, 175, 176,\n",
            "       176, 176, 176, 176, 176, 176, 176, 177, 177, 177, 177, 177, 177,\n",
            "       177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 178, 178, 178,\n",
            "       178, 178, 178, 178, 178, 178, 178, 178, 179, 179, 179, 179, 179,\n",
            "       179, 179, 179, 179, 179, 179, 179, 181, 181, 181, 181, 181, 181,\n",
            "       181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181, 181,\n",
            "       181, 181, 181, 181, 181, 182, 182, 182, 182, 189, 189, 189, 189,\n",
            "       189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189, 189,\n",
            "       189, 189, 189, 194, 194, 196, 196, 196, 196, 197, 197, 197, 197,\n",
            "       197, 197, 198, 198, 198, 199, 199, 199, 204, 204, 204, 204, 204,\n",
            "       204, 204, 205, 205, 205, 207, 207, 207, 207, 207, 207, 207, 207,\n",
            "       207, 207, 207, 207, 208, 208, 208, 208, 208, 208, 210, 210, 210,\n",
            "       210, 213, 213, 213, 213, 213, 215, 215, 222, 222, 222, 223, 223,\n",
            "       223, 223, 223, 223, 223, 229, 229, 229, 229, 229, 229, 229, 229,\n",
            "       229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229, 229,\n",
            "       229, 232, 232, 232, 232, 232, 232, 234, 234, 234, 234, 234, 234,\n",
            "       234, 234, 234, 235, 235, 236, 236, 236, 237, 237, 237, 237, 237,\n",
            "       237, 237, 237, 242, 242, 242, 242, 242, 246, 246, 246, 246, 246,\n",
            "       246, 246, 246, 246, 246, 247, 247, 247, 247, 247, 247, 247, 247,\n",
            "       247, 248, 248, 248, 248, 249, 249, 249, 249, 249, 249, 249, 249,\n",
            "       249, 249, 251, 251, 251, 251, 251, 251, 251, 252, 252, 252, 257,\n",
            "       257, 257, 257, 257, 257, 257, 257, 257, 262, 262, 262, 262, 262,\n",
            "       262, 262, 262, 262, 262, 262, 262, 262, 262, 262, 262, 262, 263,\n",
            "       264, 264, 264, 264, 264, 264, 264, 264, 264, 264, 264, 264, 264,\n",
            "       264, 264, 264, 264, 264, 264, 264, 264, 264, 264, 264, 264, 264,\n",
            "       264, 264, 264, 266, 266, 266, 266, 266, 266, 270, 270, 270, 270,\n",
            "       271, 271, 271, 271, 271, 271, 271, 271, 271, 273, 273]), array([ 6,  7, 10, 11, 12, 13, 25, 26, 27, 28, 16, 17, 18, 19, 20, 21, 22,\n",
            "       23, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 22, 23, 24, 25,\n",
            "       43, 44, 45, 46,  7, 16, 17, 10, 11, 12, 11, 12, 13, 15, 16, 17,  6,\n",
            "        7, 19, 20,  4,  5,  6, 23, 24, 25, 41, 42, 43, 44,  9, 10, 11, 12,\n",
            "       13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
            "       30, 31, 32, 33, 34, 24, 25, 28, 29, 30, 31, 32, 33, 34,  6,  7,  8,\n",
            "       30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 18, 19, 20, 13, 14, 15, 16,\n",
            "       17,  4,  5,  6,  7, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,  5,  6,\n",
            "        7, 24, 29, 30, 31, 13, 14, 26, 27, 28, 19, 20, 21, 43, 44, 45,  2,\n",
            "        3,  2,  3,  4, 21, 22, 23, 24, 13, 14, 15, 16, 17, 18, 19, 16, 17,\n",
            "       64, 65, 66, 67, 12, 13, 14, 15, 16, 29, 30, 31, 32, 33, 34, 36, 37,\n",
            "       38, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 21, 22, 33, 34, 41, 42,\n",
            "       51, 52, 53, 54, 20, 21, 31, 32, 33, 34, 35, 11, 12, 13, 13, 14, 41,\n",
            "       42, 43, 44, 45, 46, 47, 48, 49, 50, 15, 16, 17, 18, 19, 20, 23, 24,\n",
            "       25,  4,  5,  6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 18, 19, 52,\n",
            "       53, 54, 15, 16, 17, 18, 19, 20, 21, 13, 14, 15, 16, 24, 25, 26, 10,\n",
            "       11, 29, 30, 31, 32, 35, 36, 37, 38, 19, 20,  6,  7, 26, 27, 28, 29,\n",
            "       30, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31,\n",
            "       33, 34, 23, 24, 25, 26, 27, 20, 21, 22, 23, 24, 25, 26, 34, 35, 36,\n",
            "       55, 56, 57, 61, 62, 19, 20, 21, 22, 23, 24, 14, 15, 16, 31, 32, 33,\n",
            "       34, 35, 36, 37, 38, 19, 20, 21, 22, 26, 27, 28, 29, 30, 31, 32, 33,\n",
            "       34, 41, 42, 43, 15, 16, 18, 19, 20, 28, 29, 30, 31, 32, 33, 10, 11,\n",
            "       12, 13, 20, 21, 22, 23, 24, 28, 29, 30,  8,  9, 10, 11, 12, 13, 14,\n",
            "       15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n",
            "       18, 19, 20, 21,  5,  6,  7,  8,  9, 10, 25, 26, 27, 28, 29, 30, 31,\n",
            "       32, 33, 34, 35, 36, 37, 38,  5,  6, 29, 30, 31, 32,  9, 10, 17, 18,\n",
            "       19, 20, 11, 12, 13, 28, 29, 30, 10, 11, 12, 13, 14, 15, 16, 16, 17,\n",
            "       18,  7,  8, 16, 17, 18, 28, 29, 30, 31, 33, 34, 35, 15, 16, 17, 18,\n",
            "       19, 20, 75, 76, 77, 78,  9, 10, 11, 12, 13,  9, 10, 10, 11, 12, 18,\n",
            "       19, 31, 32, 33, 34, 35, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 24,\n",
            "       26, 27, 28, 29, 30, 31, 32, 33, 34, 38, 39, 15, 16, 17, 18, 19, 20,\n",
            "       19, 20, 21, 22, 23, 26, 27, 28, 29, 10, 11,  9, 10, 11, 37, 38, 39,\n",
            "       40, 41, 42, 43, 44, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29,\n",
            "       30, 31, 32,  7,  8,  9, 10, 11, 12, 13, 14, 15, 31, 32, 33, 34,  4,\n",
            "        5,  6,  7,  8,  9, 26, 27, 28, 29, 20, 21, 22, 23, 24, 25, 26, 21,\n",
            "       22, 23, 21, 22, 23, 24, 31, 32, 33, 34, 36, 20, 21, 22, 24, 25, 26,\n",
            "       28, 29, 30, 31, 32, 38, 39, 40, 42, 43, 44, 16,  9, 10, 11, 12, 13,\n",
            "       14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 35,\n",
            "       36, 37, 38, 39, 40, 41, 42, 26, 27, 28, 29, 30, 31, 23, 24, 30, 31,\n",
            "        1,  2,  3,  4,  5,  6,  7,  8,  9, 30, 31]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOE3f5NeyI-x"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lyUa1kGC-Ie",
        "outputId": "1142522f-b540-496a-9249-c97b2c001487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(count)\n",
        "print(count_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "103\n",
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqdgJERNyQwS"
      },
      "source": [
        "train_data = TensorDataset(torch.from_numpy(train_seq), torch.from_numpy(train_mask),torch.from_numpy(train_y))\n",
        "val_data = TensorDataset(torch.from_numpy(val_seq), torch.from_numpy(val_mask),torch.from_numpy(val_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZaNtKTj3gKc"
      },
      "source": [
        "batch_size = 38\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size = batch_size)\n",
        "val_loader = DataLoader(val_data, shuffle=True, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGOHnpa1rCf4"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDuWgPEE8u0z"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3mJ6kDT-f5z"
      },
      "source": [
        "i=0\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwIQstJB9Gug"
      },
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert, embed_dim, hidden_dim, drop_prob, n_layers, out_dim):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      self.bilstm = nn.LSTM(embed_dim, hidden_dim, n_layers,dropout=drop_prob,  bidirectional=True, batch_first=True)\n",
        "      self.dropout = nn.Dropout(drop_prob)\n",
        "      self.fc1 = nn.Linear(2*hidden_dim,256)\n",
        "      self.r1=nn.Tanh()\n",
        "      self.fc2 = nn.Linear(256,out_dim)\n",
        "      self.sf = nn.Sigmoid()\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      embed, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "      x,_ = self.bilstm(embed)\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc1(x)\n",
        "      x = self.r1(x)\n",
        "      x = self.fc2(x)\n",
        "      x = self.sf(x)\n",
        "\n",
        "      return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wfda-RiBcIF"
      },
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM_kbuGo9zmI",
        "outputId": "b88fd9cb-49d2-4a67-81af-722b7628c5bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "bert_model = BERT_Arch(model, 768, 256, 0.5, 1,1)\n",
        "bert_model = bert_model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i0TYZKb-gWA",
        "outputId": "c6f0a991-5dc5-481a-b63f-91bba3751a68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "weights = torch.tensor([remain,count,measure], dtype=torch.float32)\n",
        "weights = weights / weights.sum()\n",
        "print(weights)\n",
        "weights = 1.0 / weights\n",
        "weights = weights / weights.sum()\n",
        "print(weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.9294, 0.0022, 0.0684])\n",
            "tensor([0.0023, 0.9669, 0.0309])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s07zlqdxfGMy"
      },
      "source": [
        "def weighted_binary_cross_entropy(output, target, weights=None):\n",
        "    output = torch.clamp(output,min=1e-8,max=1-1e-8)\n",
        "\n",
        "    if weights is not None:\n",
        "        assert len(weights) == 2\n",
        "        loss = weights[1] * (target * torch.log(output)) + \\\n",
        "               weights[0] * ((1 - target) * torch.log(1 - output))\n",
        "    else:\n",
        "        loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n",
        "\n",
        "    return torch.neg(torch.mean(loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wh9H4gU-Jtu"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "#criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
        "criterion=nn.BCELoss()\n",
        "optimizer = AdamW(bert_model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w_LyoHS_FBJ",
        "outputId": "ffb0fa80-36fe-4d38-86c5-a6a5b4e0bf92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 10\n",
        "for e in range(epochs):\n",
        "  \n",
        "  bert_model.train()\n",
        "  i=0\n",
        "  train_loss=0\n",
        "  for seq, mask, y in train_loader:\n",
        "    bert_model.zero_grad()\n",
        "    \n",
        "    y_pred = bert_model(seq.to(device), mask.to(device))\n",
        "    #y_pred = torch.transpose(y_pred, 2,1)\n",
        "    #y = torch.transpose(y, 2,1)\n",
        "    \n",
        "    #_, given = y.max(dim=1)\n",
        "\n",
        "    # print(given)\n",
        "   \n",
        "   \n",
        "    \n",
        "    #loss = criterion(y_pred,y.to(device).float())\n",
        "    weights = [1,500]\n",
        "    loss = weighted_binary_cross_entropy(y_pred,y.to(device).float(),weights)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()*batch_size\n",
        "    if(i%5==0):\n",
        "      print(\"Epoch-{}/{} Iterations-{} loss-{}\".format(e+1,epochs,i+1,loss.item()))\n",
        "    i+=1\n",
        "  \n",
        "  \n",
        "  bert_model.eval()\n",
        "  val_loss=0\n",
        "  for seq, mask, y in val_loader:\n",
        "    bert_model.zero_grad()\n",
        "    y_pred = bert_model(seq.to(device), mask.to(device))\n",
        "    #y_pred = torch.transpose(y_pred, 2,1)\n",
        "    #y = torch.transpose(y, 2,1)\n",
        "    \n",
        "    #_, given = y.max(dim=1)\n",
        "   \n",
        "   \n",
        "    \n",
        "    loss = criterion(y_pred,y.to(device).float())\n",
        "    val_loss += loss.item()*batch_size\n",
        "    \n",
        "    i+=1\n",
        "  \n",
        "  print(\"Epoch-{}/{} train_loss-{} Val_loss-{}\".format(e+1,epochs,train_loss/len(train_loader),val_loss/len(val_loader)))\n",
        "    \n",
        "torch.save(bert_model,'/content/drive/My Drive/Model/CountvsMeasurement_AG.pt')\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch-1/10 Iterations-1 loss-0.0003867462510243058\n",
            "Epoch-1/10 Iterations-6 loss-0.0012359821703284979\n",
            "Epoch-1/10 Iterations-11 loss-0.024907639250159264\n",
            "Epoch-1/10 Iterations-16 loss-0.0013822285691276193\n",
            "Epoch-1/10 Iterations-21 loss-0.0019857753068208694\n",
            "Epoch-1/10 Iterations-26 loss-0.002813029568642378\n",
            "Epoch-1/10 Iterations-31 loss-0.0014198861317709088\n",
            "Epoch-1/10 Iterations-36 loss-0.0005948073230683804\n",
            "Epoch-1/10 train_loss-0.0893180921903459 Val_loss-0.03840237687109038\n",
            "Epoch-2/10 Iterations-1 loss-0.00036594035918824375\n",
            "Epoch-2/10 Iterations-6 loss-0.0007111646118573844\n",
            "Epoch-2/10 Iterations-11 loss-0.0008884160779416561\n",
            "Epoch-2/10 Iterations-16 loss-0.01547953486442566\n",
            "Epoch-2/10 Iterations-21 loss-0.0027730134315788746\n",
            "Epoch-2/10 Iterations-26 loss-0.0027384813874959946\n",
            "Epoch-2/10 Iterations-31 loss-0.002487498801201582\n",
            "Epoch-2/10 Iterations-36 loss-0.0017461031675338745\n",
            "Epoch-2/10 train_loss-0.08498572123711268 Val_loss-0.04873000384638241\n",
            "Epoch-3/10 Iterations-1 loss-0.0008494635694660246\n",
            "Epoch-3/10 Iterations-6 loss-0.0007129893638193607\n",
            "Epoch-3/10 Iterations-11 loss-0.0013187841977924109\n",
            "Epoch-3/10 Iterations-16 loss-0.0006557742599397898\n",
            "Epoch-3/10 Iterations-21 loss-0.0009969109669327736\n",
            "Epoch-3/10 Iterations-26 loss-0.0038381642661988735\n",
            "Epoch-3/10 Iterations-31 loss-0.0030666745733469725\n",
            "Epoch-3/10 Iterations-36 loss-0.0006703748949803412\n",
            "Epoch-3/10 train_loss-0.05599575014796731 Val_loss-0.05882475246471586\n",
            "Epoch-4/10 Iterations-1 loss-0.0018848200561478734\n",
            "Epoch-4/10 Iterations-6 loss-0.0010373161640018225\n",
            "Epoch-4/10 Iterations-11 loss-0.0006952208932489157\n",
            "Epoch-4/10 Iterations-16 loss-0.0006029216456227005\n",
            "Epoch-4/10 Iterations-21 loss-0.001027412828989327\n",
            "Epoch-4/10 Iterations-26 loss-0.0017226750496774912\n",
            "Epoch-4/10 Iterations-31 loss-0.0032575710210949183\n",
            "Epoch-4/10 Iterations-36 loss-0.000764988362789154\n",
            "Epoch-4/10 train_loss-0.052311318098627206 Val_loss-0.04470683850619631\n",
            "Epoch-5/10 Iterations-1 loss-0.0008118312689475715\n",
            "Epoch-5/10 Iterations-6 loss-0.0017158951377496123\n",
            "Epoch-5/10 Iterations-11 loss-0.00040642041130922735\n",
            "Epoch-5/10 Iterations-16 loss-0.001251464826054871\n",
            "Epoch-5/10 Iterations-21 loss-0.0003230301954317838\n",
            "Epoch-5/10 Iterations-26 loss-0.010502138175070286\n",
            "Epoch-5/10 Iterations-31 loss-0.005098277237266302\n",
            "Epoch-5/10 Iterations-36 loss-0.007537085097283125\n",
            "Epoch-5/10 train_loss-0.11522181915820143 Val_loss-0.17137868461819986\n",
            "Epoch-6/10 Iterations-1 loss-0.004675028845667839\n",
            "Epoch-6/10 Iterations-6 loss-0.00127334741409868\n",
            "Epoch-6/10 Iterations-11 loss-0.0015675240429118276\n",
            "Epoch-6/10 Iterations-16 loss-0.032701920717954636\n",
            "Epoch-6/10 Iterations-21 loss-0.0017220723675563931\n",
            "Epoch-6/10 Iterations-26 loss-0.003082068869844079\n",
            "Epoch-6/10 Iterations-31 loss-0.001757886609993875\n",
            "Epoch-6/10 Iterations-36 loss-0.0034546032547950745\n",
            "Epoch-6/10 train_loss-0.12215295663721722 Val_loss-0.037043144620838575\n",
            "Epoch-7/10 Iterations-1 loss-0.002689806977286935\n",
            "Epoch-7/10 Iterations-6 loss-0.001347969169728458\n",
            "Epoch-7/10 Iterations-11 loss-0.014931484125554562\n",
            "Epoch-7/10 Iterations-16 loss-0.028027918189764023\n",
            "Epoch-7/10 Iterations-21 loss-0.0098741939291358\n",
            "Epoch-7/10 Iterations-26 loss-0.010084625333547592\n",
            "Epoch-7/10 Iterations-31 loss-0.0007405967335216701\n",
            "Epoch-7/10 Iterations-36 loss-0.0014454084448516369\n",
            "Epoch-7/10 train_loss-0.16126107692655972 Val_loss-0.025247117094598554\n",
            "Epoch-8/10 Iterations-1 loss-0.0005205272464081645\n",
            "Epoch-8/10 Iterations-6 loss-0.00017957549425773323\n",
            "Epoch-8/10 Iterations-11 loss-0.001931417966261506\n",
            "Epoch-8/10 Iterations-16 loss-0.002352998359128833\n",
            "Epoch-8/10 Iterations-21 loss-0.0012277252972126007\n",
            "Epoch-8/10 Iterations-26 loss-0.0025594737380743027\n",
            "Epoch-8/10 Iterations-31 loss-0.0011027023429051042\n",
            "Epoch-8/10 Iterations-36 loss-0.0016513102455064654\n",
            "Epoch-8/10 train_loss-0.04311644182254551 Val_loss-0.06311836190676938\n",
            "Epoch-9/10 Iterations-1 loss-0.0036497185938060284\n",
            "Epoch-9/10 Iterations-6 loss-0.0018619587644934654\n",
            "Epoch-9/10 Iterations-11 loss-0.002210945589467883\n",
            "Epoch-9/10 Iterations-16 loss-0.0014081111876294017\n",
            "Epoch-9/10 Iterations-21 loss-0.0016041339840739965\n",
            "Epoch-9/10 Iterations-26 loss-0.0004715333634521812\n",
            "Epoch-9/10 Iterations-31 loss-0.001032862812280655\n",
            "Epoch-9/10 Iterations-36 loss-0.003205580171197653\n",
            "Epoch-9/10 train_loss-0.037546164095884536 Val_loss-0.021559611743517355\n",
            "Epoch-10/10 Iterations-1 loss-0.000253027566941455\n",
            "Epoch-10/10 Iterations-6 loss-0.000750743958633393\n",
            "Epoch-10/10 Iterations-11 loss-0.0002164664474548772\n",
            "Epoch-10/10 Iterations-16 loss-0.0003277371288277209\n",
            "Epoch-10/10 Iterations-21 loss-0.001740018604323268\n",
            "Epoch-10/10 Iterations-26 loss-3.2838932384038344e-05\n",
            "Epoch-10/10 Iterations-31 loss-0.001360603841021657\n",
            "Epoch-10/10 Iterations-36 loss-0.0019055689917877316\n",
            "Epoch-10/10 train_loss-0.030161075155184656 Val_loss-0.02205187167085872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoNOQRYmAgPq"
      },
      "source": [
        "count_total=0\n",
        "count_pred=0\n",
        "meas_total=0\n",
        "meas_pred=0\n",
        "remain_total=0\n",
        "remain_pred=0\n",
        "for seq, mask, y in val_loader:\n",
        "    bert_model.zero_grad()\n",
        "    bert_model.eval()\n",
        "    y_pred = bert_model(seq.to(device), mask.to(device))\n",
        "    #y_pred = torch.transpose(y_pred, 2,1)\n",
        "    #y = torch.transpose(y, 2,1)\n",
        "    \n",
        "    #_, target = y.max(dim=1)\n",
        "    #_, predicted=y_pred.max(dim=1)\n",
        "    target = y.cpu().data.numpy()\n",
        "    predicted = y_pred.cpu().data.numpy()\n",
        "    \n",
        "    # print(target.shape,predicted.shape)\n",
        "    for i in range(len(target)):\n",
        "      for j in range(len(target[i])):\n",
        "        if(target[i][j]==0):\n",
        "          if(target[i][j]==predicted[i][j]):\n",
        "            remain_pred+=1\n",
        "          remain_total+=1\n",
        "\n",
        "        elif(target[i][j]==1):\n",
        "          if(target[i][j]==predicted[i][j]):\n",
        "            count_pred+=1\n",
        "          count_total+=1\n",
        "\n",
        "        elif(target[i][j]==2):\n",
        "          if(target[i][j]==predicted[i][j]):\n",
        "            meas_pred+=1\n",
        "          meas_total+=1\n",
        "\n",
        "\n",
        "\n",
        "    # for i in range(np_out.shape[0]):\n",
        "    #   for j in range(np_out.shape[1]):\n",
        "    #     for k in range(np_out.shape[2]):\n",
        "    #       if np_out[i][j][k]>=0.2:\n",
        "    #         np_out[i][j][k]=1\n",
        "    #       else:\n",
        "    #         np_out[i][j][k]=0\n",
        "    \n",
        "    \n",
        "    #print(np.where(np_out==1))\n",
        "    #print(\"##########\")\n",
        "    #print(np.where(np_act==1))\n",
        "\n",
        "    # for i in range(np_out.shape[0]):\n",
        "    #   for j in range(np_out.shape[1]):\n",
        "    #     if np.max(np_out[i,j,:])==1 or np.max(np_act[i,j,:])==1:\n",
        "    #       if np.max(np_out[i,j,:])==1 and np.max(np_act[i,j,:])==1:\n",
        "    #         pos = pos + 1\n",
        "    #       else:\n",
        "    #         neg = neg + 1\n",
        "\n",
        "    # /for i in range(np_out.shape[0]):\n",
        "    #  for j in range(np_out.shape[1]):\n",
        "    #    for k in range(np_out.shape[2]):\n",
        "    #      if (np_out[i,j,k])==1 or (np_act[i,j,k])==1:\n",
        "    #        if (np_out[i,j,k])==1 and (np_act[i,j,k])==1:\n",
        "    #          pos = pos + 1\n",
        "    #        else:\n",
        "    #          neg = neg + 1\n",
        "\n",
        "# print(pos/(pos+neg))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5ZWIYzCUO_d",
        "outputId": "82d0efeb-0381-42cb-d2c7-785feb6a63a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(meas_pred,meas_total)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6th6DLrX7OS5",
        "outputId": "7b286fce-763e-41cc-ae3a-f8561a789d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "best_threshold=[]\n",
        "for k in range(1):\n",
        "  m=0\n",
        "  best_t=0\n",
        "  prec_num = 0 \n",
        "  prec_den = 0\n",
        "  rec_num = 0\n",
        "  rec_den = 0 \n",
        "  threshold = np.linspace(0.1,0.99,10)\n",
        "  f1 = []\n",
        "  pre = []\n",
        "  rec = []\n",
        "  for t in threshold:\n",
        "    for seq, mask, y in val_loader:\n",
        "      bert_model.zero_grad()\n",
        "      bert_model.eval()\n",
        "      y_pred = bert_model(seq.to(device), mask.to(device))\n",
        "      np_out = y_pred.cpu().data.numpy()\n",
        "      np_act = y.cpu().data.numpy()\n",
        "      #print(np_out)\n",
        "    \n",
        "      for i in range(np_out.shape[0]):\n",
        "        for j in range(np_out.shape[1]):\n",
        "        \n",
        "          if np_out[i][j][k]>=t:\n",
        "            np_out[i][j][k]=1\n",
        "          else:\n",
        "            np_out[i][j][k]=0\n",
        "\n",
        "      for i in range(np_out.shape[0]):\n",
        "        for j in range(np_out.shape[1]):\n",
        "          if np_out[i,j,k]==1:\n",
        "            if np_out[i,j,k]==np_act[i,j,k]:\n",
        "              prec_num = prec_num + 1\n",
        "            else:\n",
        "              prec_den = prec_den + 1\n",
        "          if np_act[i,j,k]==1:\n",
        "            if np_out[i,j,k]==np_act[i,j,k]:\n",
        "              rec_num = rec_num + 1\n",
        "            else:\n",
        "              rec_den = rec_den + 1\n",
        "\n",
        "    precision = prec_num/(prec_num+prec_den)\n",
        "    recall = rec_num/(rec_num+rec_den)\n",
        "    F1 = 2*precision*recall/(precision+recall)\n",
        "    f1.append(F1)\n",
        "    pre.append(precision)\n",
        "    rec.append(recall)\n",
        "    if F1>m:\n",
        "      best_t = t\n",
        "    m = max(m,F1)\n",
        "  best_threshold.append(best_t)\n",
        "  plt.plot(threshold,pre)\n",
        "  plt.plot(threshold,rec)\n",
        "  plt.plot(threshold,f1)\n",
        "  plt.show()\n",
        "print(best_threshold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.99]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOoKf5Y8dS6i",
        "outputId": "027dedb4-5240-4da8-991b-4401a19b0003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "p=0\n",
        "n=0\n",
        "pos=0\n",
        "neg=0\n",
        "prec_num = 0 \n",
        "prec_den = 0\n",
        "rec_num = 0\n",
        "rec_den = 0 \n",
        "p1 = 0\n",
        "n1=0\n",
        "for seq, mask, y in train_loader:\n",
        "    bert_model.zero_grad()\n",
        "    bert_model.eval()\n",
        "    y_pred = bert_model(seq.to(device), mask.to(device))\n",
        "    np_out = y_pred.cpu().data.numpy()\n",
        "    np_act = y.cpu().data.numpy()\n",
        "    \n",
        "    \n",
        "    for i in range(np_out.shape[0]):\n",
        "      for j in range(np_out.shape[1]):\n",
        "        for k in range(np_out.shape[2]):\n",
        "          if np_out[i][j][k]>=0.99:\n",
        "            np_out[i][j][k]=1\n",
        "          else:\n",
        "            np_out[i][j][k]=0\n",
        "\n",
        "    for i in range(np_out.shape[0]):\n",
        "      for j in range(np_out.shape[1]):\n",
        "        if np.max(np_out[i,j,:])==1 or np.max(np_act[i,j,:])==1:\n",
        "          if np.max(np_out[i,j,:])==1 and np.max(np_act[i,j,:])==1:\n",
        "            p1 = p1 + 1\n",
        "          else:\n",
        "            n1 = n1 + 1\n",
        "\n",
        "    for i in range(np_out.shape[0]):\n",
        "      for j in range(np_out.shape[1]):\n",
        "        for k in range(np_out.shape[2]):\n",
        "          if np_out[i,j,k] == np_act[i,j,k]:\n",
        "            p = p +1\n",
        "          else:\n",
        "            n=n+1\n",
        "          if (np_out[i,j,k])==1 or (np_act[i,j,k])==1:\n",
        "            if (np_out[i,j,k])==1 and (np_act[i,j,k])==1:\n",
        "              pos = pos + 1\n",
        "            else:\n",
        "              neg = neg + 1\n",
        "          if np_out[i,j,k]==1:\n",
        "            if np_out[i,j,k]==np_act[i,j,k]:\n",
        "              prec_num = prec_num + 1\n",
        "            else:\n",
        "              prec_den = prec_den + 1\n",
        "          if np_act[i,j,k]==1:\n",
        "            if np_out[i,j,k]==np_act[i,j,k]:\n",
        "              rec_num = rec_num + 1\n",
        "            else:\n",
        "              rec_den = rec_den + 1\n",
        "\n",
        "precision = prec_num/(prec_num+prec_den)\n",
        "recall = rec_num/(rec_num+rec_den)\n",
        "F1 = 2*precision*recall/(precision+recall)\n",
        "\n",
        "print(\"Entity recognition modified accuracy:-\" + str(p1/(p1+n1)))\n",
        "print(\"--------COUNT RESULTS--------\")\n",
        "print(\"Accuracy:-\" + str(p/(n+p)))\n",
        "print(\"Modified Accuracy:-\" + str(pos/(pos+neg)))\n",
        "print(\"Precision:-\" + str(precision))\n",
        "print(\"Recall:-\" + str(recall))\n",
        "print(\"F1 score:-\"+str(F1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entity recognition modified accuracy:-0.7006802721088435\n",
            "--------COUNT RESULTS--------\n",
            "Accuracy:-0.9999372718978102\n",
            "Modified Accuracy:-0.7006802721088435\n",
            "Precision:-0.7006802721088435\n",
            "Recall:-1.0\n",
            "F1 score:-0.824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwVH7OkKBCN3",
        "outputId": "50ff5521-65db-4d26-c452-ec74002b5d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bert_model.zero_grad()\n",
        "bert_model.eval()\n",
        "y_pred = bert_model(seq.to(device), mask.to(device))\n",
        "np_out = y_pred.cpu().data.numpy()\n",
        "np_out = np_out >=0.99\n",
        "print(np.where(np_out[:,:]==1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([ 2,  7, 11, 15]), array([ 2,  8,  8, 10]), array([0, 0, 0, 0]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyCivDaYGzvS"
      },
      "source": [
        "torch.save(bert_model,'/content/drive/My Drive/Model/count_t95_f70_sirdata.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ef-v0SeWNVd"
      },
      "source": [
        "bert_model=torch.load('/content/drive/My Drive/Model/count_t95_f70_ep20_sirdata.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbaZdz0do3h7"
      },
      "source": [
        "idx2labels = {0: \"Count\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyTA2eEPXwVP"
      },
      "source": [
        "s = \"I have 2 apples in my pocket, which are 99% pure\"\n",
        "tokenized_text = tokenizer.tokenize(s)\n",
        "test_inputs = tokenizer(s,max_length = 512,padding='max_length',truncation=True, return_tensors=\"pt\")\n",
        "model.eval()\n",
        "temp = bert_model(test_inputs['input_ids'].to(device), test_inputs['attention_mask'].to(device))>=0.95"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZSPcEAObCqe",
        "outputId": "d66d3c98-0dc0-437a-e324-03c56cad9bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "for i in range(len(tokenized_text)):\n",
        "  print(tokenized_text[i] + \": \", end='')\n",
        "  for j in range(1):\n",
        "    if(temp[0][i+1][j]):\n",
        "      print(idx2labels[j] + \" \", end='')\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i: \n",
            "have: \n",
            "2: Count \n",
            "apples: \n",
            "in: \n",
            "my: \n",
            "pocket: \n",
            ",: \n",
            "which: \n",
            "are: \n",
            "99: \n",
            "%: \n",
            "pure: \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCduHstymZ6-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}