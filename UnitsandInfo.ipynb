{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UnitsandInfo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooOdK15nvy-Z",
        "outputId": "731213bf-af91-4be6-da10-85126c5cfd10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        }
      },
      "source": [
        "!pip install sklearn\n",
        "!pip install quantulum3\n",
        "!pip install transformers\n",
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
            "Collecting quantulum3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/8d/de090808d1e7f5fee3604f07e20d92dbaacf850bac65d22b9160a413f0f1/quantulum3-0.7.5-py3-none-any.whl (10.8MB)\n",
            "\u001b[K     |████████████████████████████████| 10.8MB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: inflect in /usr/local/lib/python3.6/dist-packages (from quantulum3) (2.1.0)\n",
            "Collecting num2words\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/a2/ea800689730732e27711c41beed4b2a129b34974435bdc450377ec407738/num2words-0.5.10-py3-none-any.whl (101kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.6/dist-packages (from num2words->quantulum3) (0.6.2)\n",
            "Installing collected packages: num2words, quantulum3\n",
            "Successfully installed num2words-0.5.10 quantulum3-0.7.5\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 2.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 20.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 33.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=8b914bee0c17e8dd660f1bee7b47db5ebc3829f25e1879219d33388ec94f7025\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iox4Rs7mUkU3",
        "outputId": "d34e8737-623b-4c16-9a3e-5d194ab2c7a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import os\n",
        "import re\n",
        "import io\n",
        "import pandas as pd\n",
        "import ast \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForPreTraining\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.autograd import Variable\n",
        "from torchtext import vocab\n",
        "from torchtext import data    \n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGtAcnhqvyJy",
        "outputId": "5729d93e-87e7-4ac9-8778-103d42366f2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVLb5R5uv80O",
        "outputId": "41ff5283-b6ea-40ec-85c9-9b79278988f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/MeasEval-main/data/train/train/tsv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MeasEval-main/data/train/train/tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dNmEFu3wD9t"
      },
      "source": [
        "files=os.listdir()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ38rCdswEit",
        "outputId": "c71c8cd1-6f96-4473-fa9a-4558d3293f7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/MeasEval-main/data/train/train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsrSuNMowOGs"
      },
      "source": [
        "train=[]\n",
        "for i in files:\n",
        "  \n",
        "  pathtsv=os.path.join('tsv',i[:-3]+'tsv')\n",
        "  if(not(os.path.exists(pathtsv))):\n",
        "    continue\n",
        "  \n",
        "  filetsv=pd.read_csv(pathtsv,sep = '\\t')\n",
        "  \n",
        "  entity=filetsv[['annotType','text','other']]\n",
        "  quant=entity[entity['annotType']=='Quantity']\n",
        "  quant=quant[['text','other']]\n",
        "  quant = quant.to_numpy().tolist()\n",
        "  train.append(quant)\n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWW4f63yyhIy"
      },
      "source": [
        "X=[]\n",
        "label=[]\n",
        "for i in train:\n",
        "  for j in i:\n",
        "    temp=[]\n",
        "  \n",
        "    X.append(j[0])\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    other=j[1]\n",
        "    \n",
        "    if(not pd.isnull(other)):\n",
        "      dictio=ast.literal_eval(other) \n",
        "    \n",
        "      \n",
        "      if 'unit' in dictio:\n",
        "        t=j[0].find(dictio['unit'])\n",
        "        \n",
        "        t=[m.start() for m in re.finditer(dictio['unit'],j[0])]\n",
        "        sz=len(dictio['unit'])\n",
        "        span=[]\n",
        "        for k in t:\n",
        "          span.append((k,k+sz))\n",
        "        \n",
        "        \n",
        "        label.append(span)\n",
        "        \n",
        "\n",
        "      else:\n",
        "        label.append([])\n",
        "    else:\n",
        "      label.append([])\n",
        "  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1Y_eC8ta3_2"
      },
      "source": [
        "X_train=[]\n",
        "y_train=[]\n",
        "for i in range(len(X)):\n",
        "\n",
        "  character=list(X[i]);\n",
        "  X_train.append(character)\n",
        "  l=np.zeros(64)\n",
        "  \n",
        "  for k in label[i]:\n",
        "    l[k[0]:k[1]]=1;\n",
        "  y_train.append(l)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49EWHsB7qyt0"
      },
      "source": [
        "X_train,X_val,y_train,y_val=train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtZzGnTQs0dW"
      },
      "source": [
        "\n",
        "TEXT = data.Field(tokenize='spacy',batch_first=True,include_lengths=True)\n",
        "LABEL = data.LabelField(dtype = torch.float,batch_first=True)\n",
        "TEXT.build_vocab(X_train, max_size=1000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTK9VkEe01i6"
      },
      "source": [
        "vocab_size=len(TEXT.vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4nxZ-_vzPlJ",
        "outputId": "aa51f070-ad94-4dc6-e654-e196d09a77f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "X_train=TEXT.process(X_train)[0]\n",
        "X_val=TEXT.process(X_val)[0]\n",
        "\n",
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([45,  4,  2, 18, 18,  5,  2, 33, 35,  2,  5,  9, 17, 17,  1,  1,  1,  1,\n",
              "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jf0bUrftj9r"
      },
      "source": [
        "row=X_train.shape[1]\n",
        "X_train=F.pad(input=X_train, pad=(0, 64-row, 0, 0), mode='constant', value=1)\n",
        "\n",
        "row=X_val.shape[1]\n",
        "X_val=F.pad(input=X_val, pad=(0, 64-row, 0, 0), mode='constant', value=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWZ49QRw2044"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IdSi7c9wUyg"
      },
      "source": [
        "train_data = TensorDataset(X_train, torch.from_numpy(np.asarray(y_train)))\n",
        "val_data = TensorDataset(X_val,torch.from_numpy(np.array(y_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoAqELYSsA32"
      },
      "source": [
        "batch_size = 38\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size = batch_size)\n",
        "val_loader = DataLoader(val_data, shuffle=True, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1XfqY9nU74d"
      },
      "source": [
        "lr = 1e-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIJy0gQU6xjt"
      },
      "source": [
        "class bilstm(nn.Module):\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                         batch_first=True, bidirectional=True)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(hidden_dim*2,output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self,x):\n",
        "        embeds = self.embedding(x)\n",
        "        lstm, (hn,cn)= self.lstm(embeds)\n",
        "        \n",
        "        output = self.dropout(lstm)\n",
        "        output = self.fc(output)\n",
        "        output = self.sigmoid(output) \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESxDRBXCZQFP"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  \n",
        "model = bilstm(vocab_size, 1, 100, 32, 2)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TnVjIdqZeIY",
        "outputId": "50a27d81-eea9-454a-a293-3adc5440bf0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bilstm(\n",
            "  (embedding): Embedding(84, 100)\n",
            "  (lstm): LSTM(100, 32, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBreMe27y1Eg"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA-5cjhHphDf",
        "outputId": "ebaed399-f93c-4e61-97a2-abe387630da1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epochs = 50\n",
        "for e in range(epochs):\n",
        "  \n",
        "  model.train()\n",
        "  i=0\n",
        "  train_loss=0\n",
        "  for seq, y in train_loader:\n",
        "    model.zero_grad()\n",
        "    \n",
        "    y_pred = model(seq.to(device))\n",
        "    # print(y_pred.shape)\n",
        "    loss = criterion(y_pred,y.to(device).float())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()*batch_size\n",
        "    if(i%5==0):\n",
        "      print(\"Epoch-{}/{} Iterations-{} loss-{}\".format(e+1,epochs,i+1,loss.item()))\n",
        "    i+=1\n",
        "  \n",
        "  \n",
        "  model.eval()\n",
        "  val_loss=0\n",
        "  for seq, y in val_loader:\n",
        "    model.zero_grad()\n",
        "    y_pred = model(seq.to(device))\n",
        "    loss = criterion(y_pred,y.to(device).float())\n",
        "    val_loss += loss.item()*batch_size\n",
        "    \n",
        "    i+=1\n",
        "  # if(e%5==0):\n",
        "  #   torch.save(bert_model,'/content/drive/My Drive/Model/bert_{}.pt'.format(e))\n",
        "  \n",
        "  print(\"Epoch-{}/{} train_loss-{} Val_loss-{}\".format(e+1,epochs,train_loss/len(train_loader),val_loss/len(val_loader)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([38, 64])) that is different to the input size (torch.Size([38, 64, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch-1/50 Iterations-1 loss-0.739799976348877\n",
            "Epoch-1/50 Iterations-6 loss-0.5517277121543884\n",
            "Epoch-1/50 Iterations-11 loss-0.38756266236305237\n",
            "Epoch-1/50 Iterations-16 loss-0.2553079128265381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([3, 64])) that is different to the input size (torch.Size([3, 64, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([30, 64])) that is different to the input size (torch.Size([30, 64, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch-1/50 train_loss-16.142315897345544 Val_loss-6.82407408952713\n",
            "Epoch-2/50 Iterations-1 loss-0.17642216384410858\n",
            "Epoch-2/50 Iterations-6 loss-0.13118363916873932\n",
            "Epoch-2/50 Iterations-11 loss-0.1193750873208046\n",
            "Epoch-2/50 Iterations-16 loss-0.11138272285461426\n",
            "Epoch-2/50 train_loss-5.056160780787468 Val_loss-3.9523334860801698\n",
            "Epoch-3/50 Iterations-1 loss-0.09558525681495667\n",
            "Epoch-3/50 Iterations-6 loss-0.10795371234416962\n",
            "Epoch-3/50 Iterations-11 loss-0.10170970112085342\n",
            "Epoch-3/50 Iterations-16 loss-0.06840620189905167\n",
            "Epoch-3/50 train_loss-3.5653999626636503 Val_loss-3.0697657436132433\n",
            "Epoch-4/50 Iterations-1 loss-0.0842113122344017\n",
            "Epoch-4/50 Iterations-6 loss-0.08208608627319336\n",
            "Epoch-4/50 Iterations-11 loss-0.0691002607345581\n",
            "Epoch-4/50 Iterations-16 loss-0.06082301214337349\n",
            "Epoch-4/50 train_loss-3.058369719609618 Val_loss-2.5719030991196634\n",
            "Epoch-5/50 Iterations-1 loss-0.059190887957811356\n",
            "Epoch-5/50 Iterations-6 loss-0.055361777544021606\n",
            "Epoch-5/50 Iterations-11 loss-0.06801173090934753\n",
            "Epoch-5/50 Iterations-16 loss-0.0720638632774353\n",
            "Epoch-5/50 train_loss-2.3690820623189213 Val_loss-2.074156053364277\n",
            "Epoch-6/50 Iterations-1 loss-0.049589674919843674\n",
            "Epoch-6/50 Iterations-6 loss-0.052677083760499954\n",
            "Epoch-6/50 Iterations-11 loss-0.044014107435941696\n",
            "Epoch-6/50 Iterations-16 loss-0.040411777794361115\n",
            "Epoch-6/50 train_loss-1.8906795544549824 Val_loss-1.627807892858982\n",
            "Epoch-7/50 Iterations-1 loss-0.0613122433423996\n",
            "Epoch-7/50 Iterations-6 loss-0.038171201944351196\n",
            "Epoch-7/50 Iterations-11 loss-0.03224926441907883\n",
            "Epoch-7/50 Iterations-16 loss-0.02959434688091278\n",
            "Epoch-7/50 train_loss-1.4370988108217717 Val_loss-1.2974864095449448\n",
            "Epoch-8/50 Iterations-1 loss-0.030789151787757874\n",
            "Epoch-8/50 Iterations-6 loss-0.033343635499477386\n",
            "Epoch-8/50 Iterations-11 loss-0.020732851698994637\n",
            "Epoch-8/50 Iterations-16 loss-0.026862001046538353\n",
            "Epoch-8/50 train_loss-1.1179909430444241 Val_loss-1.074355661123991\n",
            "Epoch-9/50 Iterations-1 loss-0.02068396285176277\n",
            "Epoch-9/50 Iterations-6 loss-0.02338125929236412\n",
            "Epoch-9/50 Iterations-11 loss-0.026671111583709717\n",
            "Epoch-9/50 Iterations-16 loss-0.022061191499233246\n",
            "Epoch-9/50 train_loss-0.8808127218857408 Val_loss-0.9822718665003777\n",
            "Epoch-10/50 Iterations-1 loss-0.02658928744494915\n",
            "Epoch-10/50 Iterations-6 loss-0.01608273573219776\n",
            "Epoch-10/50 Iterations-11 loss-0.021071113646030426\n",
            "Epoch-10/50 Iterations-16 loss-0.016535786911845207\n",
            "Epoch-10/50 train_loss-0.7371436839923262 Val_loss-0.9267540577799082\n",
            "Epoch-11/50 Iterations-1 loss-0.02254432439804077\n",
            "Epoch-11/50 Iterations-6 loss-0.011452035047113895\n",
            "Epoch-11/50 Iterations-11 loss-0.018072746694087982\n",
            "Epoch-11/50 Iterations-16 loss-0.017225351184606552\n",
            "Epoch-11/50 train_loss-0.6633620337583125 Val_loss-0.8780488383024931\n",
            "Epoch-12/50 Iterations-1 loss-0.009796599857509136\n",
            "Epoch-12/50 Iterations-6 loss-0.013443967327475548\n",
            "Epoch-12/50 Iterations-11 loss-0.010055986233055592\n",
            "Epoch-12/50 Iterations-16 loss-0.018021369352936745\n",
            "Epoch-12/50 train_loss-0.5327335246372968 Val_loss-0.818278769776225\n",
            "Epoch-13/50 Iterations-1 loss-0.017321433871984482\n",
            "Epoch-13/50 Iterations-6 loss-0.00851940643042326\n",
            "Epoch-13/50 Iterations-11 loss-0.013831897638738155\n",
            "Epoch-13/50 Iterations-16 loss-0.011095920577645302\n",
            "Epoch-13/50 train_loss-0.4727507288102061 Val_loss-0.7857597801834345\n",
            "Epoch-14/50 Iterations-1 loss-0.015826646238565445\n",
            "Epoch-14/50 Iterations-6 loss-0.010008127428591251\n",
            "Epoch-14/50 Iterations-11 loss-0.009672675281763077\n",
            "Epoch-14/50 Iterations-16 loss-0.012482908554375172\n",
            "Epoch-14/50 train_loss-0.4327580918092281 Val_loss-0.8468368887901306\n",
            "Epoch-15/50 Iterations-1 loss-0.012546229176223278\n",
            "Epoch-15/50 Iterations-6 loss-0.0062778303399682045\n",
            "Epoch-15/50 Iterations-11 loss-0.008628756739199162\n",
            "Epoch-15/50 Iterations-16 loss-0.007080120500177145\n",
            "Epoch-15/50 train_loss-0.47449610023759303 Val_loss-0.8376014329493046\n",
            "Epoch-16/50 Iterations-1 loss-0.012329882942140102\n",
            "Epoch-16/50 Iterations-6 loss-0.011658594943583012\n",
            "Epoch-16/50 Iterations-11 loss-0.012384581379592419\n",
            "Epoch-16/50 Iterations-16 loss-0.007434581406414509\n",
            "Epoch-16/50 train_loss-0.38237664019688966 Val_loss-0.7446373410522937\n",
            "Epoch-17/50 Iterations-1 loss-0.0073691802099347115\n",
            "Epoch-17/50 Iterations-6 loss-0.009335855022072792\n",
            "Epoch-17/50 Iterations-11 loss-0.01736924797296524\n",
            "Epoch-17/50 Iterations-16 loss-0.009051026776432991\n",
            "Epoch-17/50 train_loss-0.40930369035340847 Val_loss-0.7744797300547361\n",
            "Epoch-18/50 Iterations-1 loss-0.009649569168686867\n",
            "Epoch-18/50 Iterations-6 loss-0.010994574055075645\n",
            "Epoch-18/50 Iterations-11 loss-0.009459463879466057\n",
            "Epoch-18/50 Iterations-16 loss-0.009371738880872726\n",
            "Epoch-18/50 train_loss-0.31425769089255484 Val_loss-0.7791758686304092\n",
            "Epoch-19/50 Iterations-1 loss-0.008594163693487644\n",
            "Epoch-19/50 Iterations-6 loss-0.011785301379859447\n",
            "Epoch-19/50 Iterations-11 loss-0.0063971844501793385\n",
            "Epoch-19/50 Iterations-16 loss-0.005202865228056908\n",
            "Epoch-19/50 train_loss-0.28287101967725903 Val_loss-0.8032551381736994\n",
            "Epoch-20/50 Iterations-1 loss-0.01220411341637373\n",
            "Epoch-20/50 Iterations-6 loss-0.005694514140486717\n",
            "Epoch-20/50 Iterations-11 loss-0.004713729023933411\n",
            "Epoch-20/50 Iterations-16 loss-0.006977802142500877\n",
            "Epoch-20/50 train_loss-0.2628387238830328 Val_loss-0.8053610177710653\n",
            "Epoch-21/50 Iterations-1 loss-0.015778517350554466\n",
            "Epoch-21/50 Iterations-6 loss-0.007781726773828268\n",
            "Epoch-21/50 Iterations-11 loss-0.005828094203025103\n",
            "Epoch-21/50 Iterations-16 loss-0.004882187582552433\n",
            "Epoch-21/50 train_loss-0.25733220679685476 Val_loss-0.8055681711062789\n",
            "Epoch-22/50 Iterations-1 loss-0.005672825034707785\n",
            "Epoch-22/50 Iterations-6 loss-0.003088144352659583\n",
            "Epoch-22/50 Iterations-11 loss-0.0035249011125415564\n",
            "Epoch-22/50 Iterations-16 loss-0.011236964724957943\n",
            "Epoch-22/50 train_loss-0.23386804603505879 Val_loss-0.8342781037092208\n",
            "Epoch-23/50 Iterations-1 loss-0.01197300385683775\n",
            "Epoch-23/50 Iterations-6 loss-0.008697216399013996\n",
            "Epoch-23/50 Iterations-11 loss-0.003746585687622428\n",
            "Epoch-23/50 Iterations-16 loss-0.0023514472413808107\n",
            "Epoch-23/50 train_loss-0.2306111171026714 Val_loss-0.8283271256834268\n",
            "Epoch-24/50 Iterations-1 loss-0.008525642566382885\n",
            "Epoch-24/50 Iterations-6 loss-0.007883310317993164\n",
            "Epoch-24/50 Iterations-11 loss-0.006375105585902929\n",
            "Epoch-24/50 Iterations-16 loss-0.0051308260299265385\n",
            "Epoch-24/50 train_loss-0.20844777923775837 Val_loss-0.8466938626021147\n",
            "Epoch-25/50 Iterations-1 loss-0.006975629832595587\n",
            "Epoch-25/50 Iterations-6 loss-0.0032239523716270924\n",
            "Epoch-25/50 Iterations-11 loss-0.0039707995019853115\n",
            "Epoch-25/50 Iterations-16 loss-0.004575908184051514\n",
            "Epoch-25/50 train_loss-0.22897912699263542 Val_loss-0.8736091941595078\n",
            "Epoch-26/50 Iterations-1 loss-0.0021169723477214575\n",
            "Epoch-26/50 Iterations-6 loss-0.005580888129770756\n",
            "Epoch-26/50 Iterations-11 loss-0.0037071413826197386\n",
            "Epoch-26/50 Iterations-16 loss-0.00807142723351717\n",
            "Epoch-26/50 train_loss-0.2052106228424236 Val_loss-0.7724864162504673\n",
            "Epoch-27/50 Iterations-1 loss-0.009064378216862679\n",
            "Epoch-27/50 Iterations-6 loss-0.013354356400668621\n",
            "Epoch-27/50 Iterations-11 loss-0.001854395610280335\n",
            "Epoch-27/50 Iterations-16 loss-0.0024004033766686916\n",
            "Epoch-27/50 train_loss-0.2245330389472656 Val_loss-0.7900515638291836\n",
            "Epoch-28/50 Iterations-1 loss-0.003066018922254443\n",
            "Epoch-28/50 Iterations-6 loss-0.002270322758704424\n",
            "Epoch-28/50 Iterations-11 loss-0.007943904958665371\n",
            "Epoch-28/50 Iterations-16 loss-0.005191416013985872\n",
            "Epoch-28/50 train_loss-0.2298248177365167 Val_loss-0.9139694545418025\n",
            "Epoch-29/50 Iterations-1 loss-0.002767241792753339\n",
            "Epoch-29/50 Iterations-6 loss-0.005084844306111336\n",
            "Epoch-29/50 Iterations-11 loss-0.002894072560593486\n",
            "Epoch-29/50 Iterations-16 loss-0.007202605716884136\n",
            "Epoch-29/50 train_loss-0.19049445251002908 Val_loss-0.8121255364269018\n",
            "Epoch-30/50 Iterations-1 loss-0.009450298734009266\n",
            "Epoch-30/50 Iterations-6 loss-0.0036572744138538837\n",
            "Epoch-30/50 Iterations-11 loss-0.0018008500337600708\n",
            "Epoch-30/50 Iterations-16 loss-0.011522158980369568\n",
            "Epoch-30/50 train_loss-0.16494286805973388 Val_loss-0.8672307938337326\n",
            "Epoch-31/50 Iterations-1 loss-0.00415941933169961\n",
            "Epoch-31/50 Iterations-6 loss-0.00263221375644207\n",
            "Epoch-31/50 Iterations-11 loss-0.0024925500620156527\n",
            "Epoch-31/50 Iterations-16 loss-0.00787972193211317\n",
            "Epoch-31/50 train_loss-0.1570206220378168 Val_loss-0.8872068885713815\n",
            "Epoch-32/50 Iterations-1 loss-0.003842262551188469\n",
            "Epoch-32/50 Iterations-6 loss-0.008189237676560879\n",
            "Epoch-32/50 Iterations-11 loss-0.007362875621765852\n",
            "Epoch-32/50 Iterations-16 loss-0.0026367364916950464\n",
            "Epoch-32/50 train_loss-0.15477895931107924 Val_loss-0.8167752996087074\n",
            "Epoch-33/50 Iterations-1 loss-0.0039022117853164673\n",
            "Epoch-33/50 Iterations-6 loss-0.004038621671497822\n",
            "Epoch-33/50 Iterations-11 loss-0.0031622254755347967\n",
            "Epoch-33/50 Iterations-16 loss-0.0028333980590105057\n",
            "Epoch-33/50 train_loss-0.14772225669585168 Val_loss-0.902286833152175\n",
            "Epoch-34/50 Iterations-1 loss-0.006894273217767477\n",
            "Epoch-34/50 Iterations-6 loss-0.005289854947477579\n",
            "Epoch-34/50 Iterations-11 loss-0.008324739523231983\n",
            "Epoch-34/50 Iterations-16 loss-0.002415092196315527\n",
            "Epoch-34/50 train_loss-0.15932247010059655 Val_loss-0.7948606468737125\n",
            "Epoch-35/50 Iterations-1 loss-0.01010199636220932\n",
            "Epoch-35/50 Iterations-6 loss-0.003635863307863474\n",
            "Epoch-35/50 Iterations-11 loss-0.0015284476103261113\n",
            "Epoch-35/50 Iterations-16 loss-0.0017938694218173623\n",
            "Epoch-35/50 train_loss-0.14893967404495925 Val_loss-0.8217446368187666\n",
            "Epoch-36/50 Iterations-1 loss-0.0013656499795615673\n",
            "Epoch-36/50 Iterations-6 loss-0.002635361859574914\n",
            "Epoch-36/50 Iterations-11 loss-0.007213023025542498\n",
            "Epoch-36/50 Iterations-16 loss-0.0026568793691694736\n",
            "Epoch-36/50 train_loss-0.13795449023600667 Val_loss-0.8942147046327591\n",
            "Epoch-37/50 Iterations-1 loss-0.003965798299759626\n",
            "Epoch-37/50 Iterations-6 loss-0.002195824636146426\n",
            "Epoch-37/50 Iterations-11 loss-0.005160869564861059\n",
            "Epoch-37/50 Iterations-16 loss-0.001422006986103952\n",
            "Epoch-37/50 train_loss-0.13033535441791172 Val_loss-0.845223418623209\n",
            "Epoch-38/50 Iterations-1 loss-0.0018751701572909951\n",
            "Epoch-38/50 Iterations-6 loss-0.0019551636651158333\n",
            "Epoch-38/50 Iterations-11 loss-0.004560221917927265\n",
            "Epoch-38/50 Iterations-16 loss-0.0044802650809288025\n",
            "Epoch-38/50 train_loss-0.12328404411673546 Val_loss-0.8365958453156054\n",
            "Epoch-39/50 Iterations-1 loss-0.007253032177686691\n",
            "Epoch-39/50 Iterations-6 loss-0.0026309210807085037\n",
            "Epoch-39/50 Iterations-11 loss-0.002491049701347947\n",
            "Epoch-39/50 Iterations-16 loss-0.004253922495990992\n",
            "Epoch-39/50 train_loss-0.11919776815921068 Val_loss-0.8897842831909657\n",
            "Epoch-40/50 Iterations-1 loss-0.0025220217648893595\n",
            "Epoch-40/50 Iterations-6 loss-0.0023421768564730883\n",
            "Epoch-40/50 Iterations-11 loss-0.0013534917961806059\n",
            "Epoch-40/50 Iterations-16 loss-0.005623807664960623\n",
            "Epoch-40/50 train_loss-0.12195337329758331 Val_loss-0.8831395782530308\n",
            "Epoch-41/50 Iterations-1 loss-0.0035449599381536245\n",
            "Epoch-41/50 Iterations-6 loss-0.0018283678218722343\n",
            "Epoch-41/50 Iterations-11 loss-0.00732118496671319\n",
            "Epoch-41/50 Iterations-16 loss-0.003522987011820078\n",
            "Epoch-41/50 train_loss-0.11840631768573076 Val_loss-0.874783131480217\n",
            "Epoch-42/50 Iterations-1 loss-0.0028348236810415983\n",
            "Epoch-42/50 Iterations-6 loss-0.0017169727943837643\n",
            "Epoch-42/50 Iterations-11 loss-0.0012644435046240687\n",
            "Epoch-42/50 Iterations-16 loss-0.0023837087210267782\n",
            "Epoch-42/50 train_loss-0.2084057796280831 Val_loss-0.9764686109498143\n",
            "Epoch-43/50 Iterations-1 loss-0.002274109283462167\n",
            "Epoch-43/50 Iterations-6 loss-0.004167783539742231\n",
            "Epoch-43/50 Iterations-11 loss-0.001183713204227388\n",
            "Epoch-43/50 Iterations-16 loss-0.0030006105080246925\n",
            "Epoch-43/50 train_loss-0.1336514153284952 Val_loss-0.9455256698653102\n",
            "Epoch-44/50 Iterations-1 loss-0.003962748683989048\n",
            "Epoch-44/50 Iterations-6 loss-0.0013246460584923625\n",
            "Epoch-44/50 Iterations-11 loss-0.002116184448823333\n",
            "Epoch-44/50 Iterations-16 loss-0.0012565497308969498\n",
            "Epoch-44/50 train_loss-0.15289404077921062 Val_loss-0.8583651095628738\n",
            "Epoch-45/50 Iterations-1 loss-0.0026236579287797213\n",
            "Epoch-45/50 Iterations-6 loss-0.0028826608322560787\n",
            "Epoch-45/50 Iterations-11 loss-0.004906435031443834\n",
            "Epoch-45/50 Iterations-16 loss-0.01068783923983574\n",
            "Epoch-45/50 train_loss-0.12772031291387975 Val_loss-0.8619182843714952\n",
            "Epoch-46/50 Iterations-1 loss-0.0025182608515024185\n",
            "Epoch-46/50 Iterations-6 loss-0.004925795365124941\n",
            "Epoch-46/50 Iterations-11 loss-0.0030974179971963167\n",
            "Epoch-46/50 Iterations-16 loss-0.003213779767975211\n",
            "Epoch-46/50 train_loss-0.12878504740074276 Val_loss-0.9172894217073917\n",
            "Epoch-47/50 Iterations-1 loss-0.0007327870116569102\n",
            "Epoch-47/50 Iterations-6 loss-0.0025929331313818693\n",
            "Epoch-47/50 Iterations-11 loss-0.001120363362133503\n",
            "Epoch-47/50 Iterations-16 loss-0.002220914466306567\n",
            "Epoch-47/50 train_loss-0.09611097073066048 Val_loss-0.9501311775296927\n",
            "Epoch-48/50 Iterations-1 loss-0.001719118095934391\n",
            "Epoch-48/50 Iterations-6 loss-0.002280483255162835\n",
            "Epoch-48/50 Iterations-11 loss-0.0017556548118591309\n",
            "Epoch-48/50 Iterations-16 loss-0.0024153415579348803\n",
            "Epoch-48/50 train_loss-0.0994141709874384 Val_loss-0.9944226302206516\n",
            "Epoch-49/50 Iterations-1 loss-0.0015339239034801722\n",
            "Epoch-49/50 Iterations-6 loss-0.0030110448133200407\n",
            "Epoch-49/50 Iterations-11 loss-0.0013529830612242222\n",
            "Epoch-49/50 Iterations-16 loss-0.0017390571301802993\n",
            "Epoch-49/50 train_loss-0.09418021775054512 Val_loss-0.9427142571657896\n",
            "Epoch-50/50 Iterations-1 loss-0.0014439420774579048\n",
            "Epoch-50/50 Iterations-6 loss-0.0014175466494634748\n",
            "Epoch-50/50 Iterations-11 loss-0.006238135043531656\n",
            "Epoch-50/50 Iterations-16 loss-0.00378056219778955\n",
            "Epoch-50/50 train_loss-0.08667757938965223 Val_loss-0.9781971985474229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5_GxVcA2Nhm",
        "outputId": "0800cd15-ff01-4217-e035-53bae43c8639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pos=0\n",
        "neg=0\n",
        "units=[]\n",
        "for seq, y in val_loader:\n",
        "    model.zero_grad()\n",
        "    model.eval()\n",
        "    y_pred = model(seq.to(device))\n",
        "    np_out = y_pred.cpu().data.numpy()\n",
        "    np_act = y.cpu().data.numpy()\n",
        "    \n",
        "    np_out=np_out>=0.07\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    for i in range(np_out.shape[0]):\n",
        "     for j in range(np_out.shape[1]):\n",
        "       if (np_out[i,j])==1 or (np_act[i,j])==1:\n",
        "           if (np_out[i,j])==1 and (np_act[i,j])==1:\n",
        "             pos = pos + 1\n",
        "           else:\n",
        "             neg = neg + 1\n",
        "\n",
        "print(pos/(pos+neg))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8313253012048193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmE-sWb56Ccg",
        "outputId": "d3774a8e-6265-4656-a73f-ce7b28dc7d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.eval()\n",
        "  \n",
        "for i in range(len(X_val)):\n",
        "  answer=[]\n",
        "  t=''\n",
        "  for j in X_val[i]:\n",
        "    t=t+j\n",
        "  answer.append(t)\n",
        "  temp=[]\n",
        "  temp.append(X_val[i])\n",
        "  seq=TEXT.process(temp)[0]\n",
        "  row=seq.shape[1]\n",
        "  seq=F.pad(input=seq, pad=(0, 64-row, 0, 0), mode='constant', value=1)\n",
        "  \n",
        "  \n",
        "  y_pred = model(seq.to(device))\n",
        "  np_out = y_pred.cpu().data.numpy()\n",
        "  \n",
        "  \n",
        "    \n",
        "  \n",
        "  \n",
        "  for i in np_out:\n",
        "      \n",
        "      a1=i>=0.07\n",
        "      a1_rshifted = np.roll(a1, 1)\n",
        "\n",
        "      starts = a1 & ~a1_rshifted\n",
        "      ends = ~a1 & a1_rshifted\n",
        "      starts=np.nonzero(starts)[0]\n",
        "      ends=np.nonzero(ends)[0]\n",
        "\n",
        "      for j in range(len(starts)):\n",
        "        answer.append(t[starts[j]:ends[j]])\n",
        "\n",
        "\n",
        "  print(answer)\n",
        "      \n",
        "  \n",
        "      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['6–8%', '%']\n",
            "['≥11.1 mmol/L', 'mmol/L']\n",
            "['±70 m/s', 'm/s']\n",
            "['488 ± 14 K', 'K']\n",
            "['0.13']\n",
            "['ηnet = 0.5']\n",
            "['∼0.5–5 Å/s', 'Å/s']\n",
            "['4–7 kV', 'kV']\n",
            "['6 kg', 'kg']\n",
            "['up to 100%', '%']\n",
            "['two']\n",
            "['13 kg', 'kg']\n",
            "['1.85–2.48']\n",
            "['15']\n",
            "['1.75']\n",
            "['5 g', 'g']\n",
            "['range 1013 cm−3 to 1016 cm−3', 'cm−3', 'cm−3']\n",
            "['1.5 mm', 'mm']\n",
            "['5.65 s', 's']\n",
            "['approximately 54%', '%']\n",
            "['2.5–10 μm', 'μm']\n",
            "['over 3 byr', 'byr']\n",
            "['6967']\n",
            "['0.06–0.07 mBar', 'mBar']\n",
            "['three metre', 'met']\n",
            "['12.1%', '%']\n",
            "['23.8%', '%']\n",
            "['n=104']\n",
            "['95%', '%']\n",
            "['0.03']\n",
            "['274 elderly participants', 'ly participants']\n",
            "['35%', '%']\n",
            "['1.5‰', '‰']\n",
            "['from 211 K to 284 K', 'K', 'K']\n",
            "['< 0.001']\n",
            "['1000']\n",
            "['16 times', 'times']\n",
            "['1 (w/w)']\n",
            "['range of 34–38 °C', '°C']\n",
            "['7.5–80']\n",
            "['∼33.7 Ma', 'Ma']\n",
            "['84%', '%']\n",
            "['95%', '%']\n",
            "['above thirty percent', 'percent']\n",
            "['2619.60, 2614.73, and 2614.71 m', 'm']\n",
            "['10,308 employees', 'employees']\n",
            "['before 6 months', 'months']\n",
            "['about 40%', '%']\n",
            "['18']\n",
            "['0.51–0.85 m.', 'm']\n",
            "['< .001']\n",
            "['zero']\n",
            "['over the 9-year', 'h', 'year']\n",
            "['between 8000 and 9000 K', 'K']\n",
            "['55 K.', 'K']\n",
            "['10%', '%']\n",
            "['above 0.003 Hz', 'Hz']\n",
            "['1.8 cm', 'cm']\n",
            "['8–300']\n",
            "['65 years', 'years']\n",
            "['two']\n",
            "['0–10 cm', 'cm']\n",
            "['near 1 μbar', 'μbar']\n",
            "['8.4 mm', 'mm']\n",
            "['three']\n",
            "['13%', '%']\n",
            "['0.06']\n",
            "['F']\n",
            "['6']\n",
            "['0.64%', '%']\n",
            "['1.5 mm', 'mm']\n",
            "['≥16']\n",
            "['500']\n",
            "['86 s', 's']\n",
            "['100×']\n",
            "['1.5 mm and the 8.5 mm', 'mm', 'mm']\n",
            "['between 60% and 100%', '%']\n",
            "['1:10']\n",
            "['3.91 nm', 'nm']\n",
            "['95%', '%']\n",
            "['93:7, v/v', 'v/v']\n",
            "['five']\n",
            "['95%', '%']\n",
            "['0.01–0.03 Hz', 'Hz']\n",
            "['95%', '%']\n",
            "['3Rp', 'Rp']\n",
            "['1 μbar', 'μbar']\n",
            "['93.90±0.15 Ma', 'Ma']\n",
            "['200 μm', 'μm']\n",
            "['27 keV to 21 MeV', 'k', 'MeV']\n",
            "['35 to 55']\n",
            "['86 s, nominally', 's,', 'nom']\n",
            "['1300 K', 'K']\n",
            "['less than 2.5 μm', 'μm']\n",
            "['8.5 mm', 'mm']\n",
            "['62 mm', 'mm']\n",
            "['4.3 m', 'm']\n",
            "['greater than 20 m s−1', 'm s−1']\n",
            "['22%', '%']\n",
            "['10 min', 'min']\n",
            "['7200 K', 'K']\n",
            "['top 10 cm', 'cm']\n",
            "['above 10.5 m', 'm']\n",
            "['from ∼20 ppm to ∼180 ppm', 'ppm ', 'ppm']\n",
            "['1083 nm', 'nm']\n",
            "['less than 6 K', 'K']\n",
            "['sixteen times', 'm']\n",
            "['<0.01 ppm', 'ppm']\n",
            "['1.5 mm and 8.5 mm', 'mm ', 'mm']\n",
            "['40°N', '°N']\n",
            "['greater than 10%', '%']\n",
            "['1.14']\n",
            "['less than 1%', '%']\n",
            "['0.4 scale heights', 'sc', 'heights']\n",
            "['5318 participants', 'participants']\n",
            "['1.0 kg', 'kg']\n",
            "['6 kg', 'kg']\n",
            "['37%', '%']\n",
            "['r2=0.92']\n",
            "['past 14 days', 'pas', 'days']\n",
            "['two']\n",
            "['two']\n",
            "['ca. 0.4–1.0 nm', 'nm']\n",
            "['57°44’8.47”N; 1°50’26.59”E', '°', '°', '”E']\n",
            "['1.3 mm and 8.4 mm,', 'mm ', 'mm,']\n",
            "['near 1.4Rp', 'Rp']\n",
            "['26 October 2011']\n",
            "['5%', '%']\n",
            "['none']\n",
            "['38 °C', '°C']\n",
            "['range 66% to 88%', '%']\n",
            "['65']\n",
            "['eight-year', 'year']\n",
            "['1999']\n",
            "['(563–624) ± 30 K', 'K']\n",
            "['2.14']\n",
            "['81%', '%']\n",
            "['100 °C', '°C']\n",
            "['274 Whitehall II participants', 'Wh', 'II participants']\n",
            "['4Rp', 'Rp']\n",
            "['4.5 kg, 6 kg and 13 kg', 'kg', 'kg', 'kg']\n",
            "['5 or more', 'more']\n",
            "['147']\n",
            "['two']\n",
            "['13 kg', 'kg']\n",
            "['pH∼2', 'pH∼2']\n",
            "['650 K', 'K']\n",
            "['50 mm', 'mm']\n",
            "['<1 ppm', 'ppm']\n",
            "['2.5 years', 'years']\n",
            "['1.3 mm', 'mm']\n",
            "['∼50']\n",
            "['10 min', 'min']\n",
            "['10°', '°']\n",
            "['range of 10–15%', '%']\n",
            "['300±15 °C', '°C']\n",
            "['490 K', 'K']\n",
            "['after 13 passages', 'passages']\n",
            "['35%', '%']\n",
            "['16.2%', '%']\n",
            "['34 °C', '°C']\n",
            "['1000 times', 'times']\n",
            "['8000 K', 'K']\n",
            "['around 0.5 ms', 'ms']\n",
            "['1991 to 1993']\n",
            "['greater than 0.1 ppm', 'ppm']\n",
            "['0.4–0.6 wt.%', 'wt.%']\n",
            "['29.5°N', '°N']\n",
            "['1.37']\n",
            "['63%', '%']\n",
            "['<2 ppm', 'ppm']\n",
            "['20 eV', 'eV']\n",
            "['7000 K', 'K']\n",
            "['between 50 and 100']\n",
            "['52%', '%']\n",
            "['from 2605 m to 2634 m', 'm', 'm']\n",
            "['40%', '%']\n",
            "['20 items', 'items']\n",
            "['between 6% and 13%', '%']\n",
            "['three']\n",
            "['1 to 600 ppt', 'ppt']\n",
            "['Up to 20 m', 'm']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO2myvJdA-HJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}