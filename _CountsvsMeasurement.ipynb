{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" CountsvsMeasurement.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8e73e2a7aa9f41729a8befcca54daf63":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bed0678d4b0f435aaafed21fe6581798","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d885153c5a86401a92b014bd258989fc","IPY_MODEL_53b85c3b5c374078b05e06031697dc46"]}},"bed0678d4b0f435aaafed21fe6581798":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d885153c5a86401a92b014bd258989fc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d17432c07a89405e91d792aafeb5ca99","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b323056f9bd44ab7bf60e7bf5f11a51d"}},"53b85c3b5c374078b05e06031697dc46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ed1f064bf18e412b9842b43af67af763","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 2.88MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a7af5cfbfb6d4b4a9bd1c31d62680ea9"}},"d17432c07a89405e91d792aafeb5ca99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b323056f9bd44ab7bf60e7bf5f11a51d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed1f064bf18e412b9842b43af67af763":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a7af5cfbfb6d4b4a9bd1c31d62680ea9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"435fbc874e2d4f91bdd91c96c7a03bda":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_96a57a07626e482cb60c5445471318ce","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e11f8b722dbe4a0eaef2e93349bd2b18","IPY_MODEL_f896f9de8d424a76bc1f27564220200f"]}},"96a57a07626e482cb60c5445471318ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e11f8b722dbe4a0eaef2e93349bd2b18":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ed75e2f9a0964f3eb86a6d96673448b5","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_25e63074577d416e86d7fc1e9f4a09f8"}},"f896f9de8d424a76bc1f27564220200f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_10af06425b7c4d10b127bc6e7803d8ba","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:08&lt;00:00, 50.7B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4bf094700b1146aa87e47046b50b0709"}},"ed75e2f9a0964f3eb86a6d96673448b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"25e63074577d416e86d7fc1e9f4a09f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"10af06425b7c4d10b127bc6e7803d8ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4bf094700b1146aa87e47046b50b0709":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1d0f67137e814e7b915925d16184388c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1fed83b435794441aa9b7c881252bab0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ebcd419c09ea4fa7a18b5fe893f468ed","IPY_MODEL_2260808ba5554733925524734941eb96"]}},"1fed83b435794441aa9b7c881252bab0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ebcd419c09ea4fa7a18b5fe893f468ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1a691a7d26df48d99d0005be0c29bb06","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8b007c1ba95546afa2f1464282a85950"}},"2260808ba5554733925524734941eb96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fba0787db61b4782af380414c06378cf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:06&lt;00:00, 67.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3139e82b4e1a46c0bc44b68fcdb81727"}},"1a691a7d26df48d99d0005be0c29bb06":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8b007c1ba95546afa2f1464282a85950":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fba0787db61b4782af380414c06378cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3139e82b4e1a46c0bc44b68fcdb81727":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F_ZhOd1M9Zu-","outputId":"b7c2866b-f650-4d4b-a7df-406bcc95482f"},"source":["!pip install transformers==3.5.0\n","!pip install nltk"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers==3.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/34/fb092588df61bf33f113ade030d1cbe74fb73a0353648f8dd938a223dce7/transformers-3.5.0-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 14.7MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 50.6MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (2.23.0)\n","Collecting tokenizers==0.9.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 48.8MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (3.0.12)\n","Collecting sentencepiece==0.1.91\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 50.1MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (0.8)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (3.12.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (1.18.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.0) (20.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.0) (0.17.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.0) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.0) (3.0.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.5.0) (50.3.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.5.0) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=c900a6d2f191b933a5d23a1367fa5a4a6e627ca889006888187e8ba45a05a04b\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.0\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0fC82b_e9ikz","outputId":"e375a4ea-f26d-4440-8bd9-df8fd42f857d"},"source":["import os\n","import io\n","import pandas as pd\n","import torch\n","from transformers import BertTokenizer, BertModel, BertForPreTraining\n","import nltk\n","from sklearn.model_selection import train_test_split\n","import re\n","import ast \n","import numpy as np\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzBOj6mM9mZW","outputId":"fba3ab1a-42fe-4b06-ee5a-2574486a8a02"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WeI9yG219pOI","outputId":"68914c6a-45a8-4b25-b164-370b253474ef"},"source":["cd /content/drive/My Drive/MeasEval-main/data/train/train/text"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/MeasEval-main/data/train/train/text\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SNMG6LoY9wN3"},"source":["files=os.listdir()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PP1R_o6j9yxD","outputId":"3ed06c64-0b33-4261-e883-53946a5ca604"},"source":["cd /content/drive/My Drive/MeasEval-main/data/train/dev/text"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/MeasEval-main/data/train/dev/text\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tiDH7A5Z90xT"},"source":["files_val=os.listdir()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWsusffo929P","outputId":"2d0f1481-4cc4-4a3f-a6b9-aa9f90d226b7"},"source":["cd /content/drive/My Drive/MeasEval-main/data/train/train"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/MeasEval-main/data/train/train\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["8e73e2a7aa9f41729a8befcca54daf63","bed0678d4b0f435aaafed21fe6581798","d885153c5a86401a92b014bd258989fc","53b85c3b5c374078b05e06031697dc46","d17432c07a89405e91d792aafeb5ca99","b323056f9bd44ab7bf60e7bf5f11a51d","ed1f064bf18e412b9842b43af67af763","a7af5cfbfb6d4b4a9bd1c31d62680ea9"]},"id":"7QneEv6x947O","outputId":"d879cdaf-9932-43a9-9879-2a5945caa257"},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e73e2a7aa9f41729a8befcca54daf63","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hRSoNjzw964J"},"source":["def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n","\n","    \n","    tokenized_sentence = []\n","    labels = []\n","\n","    for word, label in zip(sentence, text_labels):\n","\n","        # Tokenize the word and count # of subwords the word is broken into\n","        tokenized_word = tokenizer.tokenize(word)\n","        n_subwords = len(tokenized_word)\n","\n","        # Add the tokenized word to the final tokenized word list\n","        tokenized_sentence.extend(tokenized_word)\n","\n","        # Add the same label to the new list of labels `n_subwords` times\n","        labels.extend([label] * n_subwords)\n","    # print(len(tokenized_sentence))\n","    # print(len(labels))\n","    return tokenized_sentence, labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6-WWjO6-99Ke"},"source":["l=0\n","NERdata=[]\n","for i in files:\n","  \n","  pathtxt=os.path.join('text',i)\n","  \n","  with open(pathtxt, 'r') as f:\n","    text=f.read()\n","  pathtsv=os.path.join('tsv',i[:-3]+'tsv')\n","  if(not(os.path.exists(pathtsv))):\n","    continue\n","  filetsv=pd.read_csv(pathtsv,sep = '\\t')\n","  entity=filetsv[['annotType','startOffset','endOffset','text','other']]\n","  entity=entity[entity['annotType']=='Quantity']\n","  \n","  entity = entity.to_numpy().tolist()\n","\n","  ent=0\n","  offset=0\n","  sent_text = nltk.sent_tokenize(text)\n","  \n","  for j in sent_text:\n","    row=[]\n","    row.append(i[:-4])\n","    \n","    \n","    ent_sen=[]\n","    ret = [(m.group(0), m.start(), m.end() - 1) for m in re.finditer(r'\\S+', j)]\n","    start=[]\n","    \n","    for word in ret:\n","      types=[]\n","      # other=[]\n","      for ent_doc in entity:\n","        \n","        if(offset+word[1]>=ent_doc[1] and offset+word[2]<=ent_doc[2]):\n","          dictio={}\n","          if(not pd.isnull(ent_doc[4])):\n","            dictio=ast.literal_eval(ent_doc[4])\n","\n","          \n","          if('mods' in dictio):\n","            info=dictio['mods']\n","            \n","            if('IsCount' in info):\n","              types.append(\"Count\")\n","              \n","            else:\n","              types.append(\"Measurement\")\n","          else:\n","            types.append(\"Measurement\")\n","\n","\n","        # print(word,types,dictio)\n","      \n","      ent_sen.append(types)     \n","    \n","    # print(ent_sen)\n","    sen,label=tokenize_and_preserve_labels(j.split(' '),ent_sen,tokenizer)\n","    label.insert(0,[])\n","    label.append([])\n","    offset+=(1+len(j))\n","    # print(j)\n","    # print(label)\n","    row.append(j)\n","    row.append(label)\n","    \n","    NERdata.append(row)\n","    \n","  \n","  \n","  \n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kL-4N_pm9_BP"},"source":["NERdf=pd.DataFrame (NERdata, columns = ['Id','Text','Entity'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VhLLUDVJ-BXo","outputId":"a48414bf-2682-467a-e8ed-a0a3e9b37988"},"source":["cd /content/drive/My Drive/MeasEval-main/data/train/dev"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/MeasEval-main/data/train/dev\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M3eMEktl-DsJ"},"source":["l=0\n","NERdata=[]\n","for i in files_val:\n","  \n","  pathtxt=os.path.join('text',i)\n","  \n","  with open(pathtxt, 'r') as f:\n","    text=f.read()\n","  pathtsv=os.path.join('tsv',i[:-3]+'tsv')\n","  if(not(os.path.exists(pathtsv))):\n","    continue\n","  filetsv=pd.read_csv(pathtsv,sep = '\\t')\n","  entity=filetsv[['annotType','startOffset','endOffset','text','other']]\n","  entity=entity[entity['annotType']=='Quantity']\n","  \n","  entity = entity.to_numpy().tolist()\n","\n","  ent=0\n","  offset=0\n","  sent_text = nltk.sent_tokenize(text)\n","  \n","  for j in sent_text:\n","    row=[]\n","    row.append(i[:-4])\n","    \n","    \n","    ent_sen=[]\n","    ret = [(m.group(0), m.start(), m.end() - 1) for m in re.finditer(r'\\S+', j)]\n","    start=[]\n","    \n","    for word in ret:\n","      types=[]\n","      # other=[]\n","      for ent_doc in entity:\n","        \n","        if(offset+word[1]>=ent_doc[1] and offset+word[2]<=ent_doc[2]):\n","          dictio={}\n","          if(not pd.isnull(ent_doc[4])):\n","            dictio=ast.literal_eval(ent_doc[4])\n","\n","          \n","          if('mods' in dictio):\n","            info=dictio['mods']\n","            \n","            if('IsCount' in info):\n","              types.append(\"Count\")\n","              \n","            else:\n","              types.append(\"Measurement\")\n","          else:\n","            types.append(\"Measurement\")\n","\n","\n","        # print(word,types,dictio)\n","      \n","      ent_sen.append(types)     \n","    \n","    # print(ent_sen)\n","    sen,label=tokenize_and_preserve_labels(j.split(' '),ent_sen,tokenizer)\n","    label.insert(0,[])\n","    label.append([])\n","    offset+=(1+len(j))\n","    # print(j)\n","    # print(label)\n","    row.append(j)\n","    row.append(label)\n","    \n","    NERdata.append(row)\n","    \n","  \n","  \n","  \n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RWReHmBw-FYx"},"source":["NERdf_val=pd.DataFrame (NERdata, columns = ['Id','Text','Entity'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D150u7DP-k7a"},"source":["def len_text(x):\n","  sum = 0\n","  for en in x:\n","    #print(en)\n","    if en==['Count']:\n","      sum += len(en)\n","  return sum"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ai0u-Bmn-H4Y"},"source":["NERdf_val[\"len\"] = NERdf_val[\"Entity\"].apply(lambda x: len_text(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pv51Qouk-JsR","outputId":"89fe8e22-0514-4425-f8c8-33d817259390"},"source":["print(NERdf_val[NERdf_val[\"len\"] != 0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["                          Id  ... len\n","0      S0031405612000728-769  ...   1\n","6     S0032063312003054-2501  ...   3\n","8     S0032063312003054-2501  ...   1\n","20    S0025322712001600-2230  ...   1\n","34     S0032063312002437-627  ...   3\n","71    S030881461301604X-1002  ...   1\n","143  S0022000014000026-18167  ...   1\n","\n","[7 rows x 4 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6-MnQSpK-Ln0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UC8ryM72-N3M"},"source":["NERdf[\"len\"] = NERdf[\"Entity\"].apply(lambda x: len_text(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWvAauvH-Pyn"},"source":["NERdf_nz = NERdf[NERdf[\"len\"] != 0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HwtIr6CW-Rjz"},"source":["#NERdf = pd.concat([NERdf_nz, NERdf_z])\n","NERdf = NERdf_nz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"N9_wbCPg-T3a","outputId":"9947f6c8-4a73-4f13-8577-bcc29fa4c71c"},"source":["NERdf.sample(frac=1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>Text</th>\n","      <th>Entity</th>\n","      <th>len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1354</th>\n","      <td>S0012821X12004384-1302</td>\n","      <td>Five samples from below the CIE at 2619.60, 26...</td>\n","      <td>[[], [Count], [], [], [], [], [], [], [], [Mea...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>986</th>\n","      <td>S0012821X13007309-1482</td>\n","      <td>The FO (first occurrence) of the ammonite Wati...</td>\n","      <td>[[], [], [Count], [Count], [], [], [], [], [],...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>361</th>\n","      <td>S0167819113001051-1247</td>\n","      <td>Although each node has 18 cores, the intended ...</td>\n","      <td>[[], [], [], [], [], [Count], [], [], [], [], ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>664</th>\n","      <td>S0167610512002292-3305</td>\n","      <td>The results from three different simulations a...</td>\n","      <td>[[], [], [], [], [Count], [], [], [], [], [], ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>627</th>\n","      <td>S016412121300188X-5038</td>\n","      <td>As an answer to RQ7, this study finds that unl...</td>\n","      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>173</th>\n","      <td>S0925443913001385-1638</td>\n","      <td>In order to estimate the effect of the MRPL12 ...</td>\n","      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>345</th>\n","      <td>S175058361300203X-1638</td>\n","      <td>We studied two cases, one where the injection ...</td>\n","      <td>[[], [], [], [Count], [], [], [], [], [], [], ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>445</th>\n","      <td>S0019103511004994-1399</td>\n","      <td>Enceladus, one out of currently 62 satellites ...</td>\n","      <td>[[], [], [], [], [], [], [], [], [], [], [Coun...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>583</th>\n","      <td>S1873506113001116-978</td>\n","      <td>Serial passaging of two different hiPSC lines ...</td>\n","      <td>[[], [], [], [], [], [Count], [], [], [], [], ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>S0006322312001096-1197</td>\n","      <td>We used three indicators (or proxy measures) t...</td>\n","      <td>[[], [], [], [Count], [], [], [], [], [], [], ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>73 rows × 4 columns</p>\n","</div>"],"text/plain":["                          Id  ... len\n","1354  S0012821X12004384-1302  ...   1\n","986   S0012821X13007309-1482  ...   2\n","361   S0167819113001051-1247  ...   1\n","664   S0167610512002292-3305  ...   1\n","627   S016412121300188X-5038  ...   1\n","...                      ...  ...  ..\n","173   S0925443913001385-1638  ...   1\n","345   S175058361300203X-1638  ...   1\n","445   S0019103511004994-1399  ...   2\n","583    S1873506113001116-978  ...   1\n","46    S0006322312001096-1197  ...   1\n","\n","[73 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"336FcQaW-V3e","outputId":"60d8855a-8fc6-49e7-a66f-4535df44bd3c"},"source":["len(NERdf)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["73"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":116,"referenced_widgets":["435fbc874e2d4f91bdd91c96c7a03bda","96a57a07626e482cb60c5445471318ce","e11f8b722dbe4a0eaef2e93349bd2b18","f896f9de8d424a76bc1f27564220200f","ed75e2f9a0964f3eb86a6d96673448b5","25e63074577d416e86d7fc1e9f4a09f8","10af06425b7c4d10b127bc6e7803d8ba","4bf094700b1146aa87e47046b50b0709","1d0f67137e814e7b915925d16184388c","1fed83b435794441aa9b7c881252bab0","ebcd419c09ea4fa7a18b5fe893f468ed","2260808ba5554733925524734941eb96","1a691a7d26df48d99d0005be0c29bb06","8b007c1ba95546afa2f1464282a85950","fba0787db61b4782af380414c06378cf","3139e82b4e1a46c0bc44b68fcdb81727"]},"id":"NCO02r4z-YRd","outputId":"c493351d-d5a5-4f0d-fe30-456e3fd489d8"},"source":["model = BertModel.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"435fbc874e2d4f91bdd91c96c7a03bda","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1d0f67137e814e7b915925d16184388c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q5_hNvsc-aJg"},"source":["text=NERdf['Text'].tolist()\n","textlabels=NERdf['Entity'].tolist()\n","\n","for i in range(len(textlabels)):\n","  textlabels[i]=(textlabels[i] + 512 * [np.zeros(3)])[:512]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rrUWsrnh-b9b"},"source":["text_val=NERdf_val['Text'].tolist()\n","textlabels_val=NERdf_val['Entity'].tolist()\n","\n","for i in range(len(textlabels_val)):\n","  textlabels_val[i]=(textlabels_val[i] + 512 * [np.zeros(3)])[:512]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TVz18aRr-eK0","outputId":"1c44f6c5-63be-410a-ee41-0845341ea442"},"source":["print(len(textlabels[0][0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jtxq5Vna-sPq"},"source":["inputs = tokenizer(text,max_length = 512,padding='max_length',truncation=True, return_tensors=\"pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fOsHWQc4-uaj"},"source":["inputs_val = tokenizer(text_val,max_length = 512,padding='max_length',truncation=True, return_tensors=\"pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2AZwHVDj-wOi"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bFCsy-4q-x_a"},"source":["train_seq = np.array(inputs['input_ids'])\n","train_mask = np.array(inputs['attention_mask'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"boJOmLFU-zw_"},"source":["val_seq = np.array(inputs_val['input_ids'])\n","val_mask = np.array(inputs_val['attention_mask'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XXij7AXK-2CH"},"source":["\n","count=0\n","\n","\n","onehot_labels = np.zeros((len(textlabels), len(textlabels[0]),1));\n","for i in range(len(textlabels)):\n","  for j in range(len(textlabels[0])):\n","    if len(textlabels[i][j])!=0:\n","      if (textlabels[i][j][0]==\"Count\"):\n","        count+=1\n","        onehot_labels[i][j][0] = 1\n","      "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDwQVgZy-6dQ"},"source":["\n","count_val=0\n","\n","\n","onehot_labels_val = np.zeros((len(textlabels_val), len(textlabels_val[0]),1));\n","for i in range(len(textlabels_val)):\n","  for j in range(len(textlabels_val[0])):\n","    if len(textlabels_val[i][j])!=0:\n","      if (textlabels_val[i][j][0]==\"Count\"):\n","        count_val+=1\n","        onehot_labels_val[i][j][0] = 1\n","      "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ha5SPqUM-9vZ"},"source":["val_y = onehot_labels_val\n","train_y = onehot_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GQfa1ghC-_ny"},"source":["from torch.utils.data import TensorDataset, DataLoader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oO7inDCv_CVy"},"source":["train_data = TensorDataset(torch.from_numpy(train_seq), torch.from_numpy(train_mask),torch.from_numpy(train_y))\n","val_data = TensorDataset(torch.from_numpy(val_seq), torch.from_numpy(val_mask),torch.from_numpy(val_y))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AB00kiQQ_ECg"},"source":["batch_size = 38\n","train_loader = DataLoader(train_data, shuffle=True, batch_size = batch_size)\n","val_loader = DataLoader(val_data, shuffle=True, batch_size = batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MUIwNyWd_Gni"},"source":["from transformers import BertTokenizer, BertModel\n","import torch\n","import torch.nn as nn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6liDTTkd_IkG"},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VS_doUKg_KN7"},"source":["i=0\n","for param in model.parameters():\n","    param.requires_grad = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jE_6ZB0f_L6C"},"source":["class BERT_Arch(nn.Module):\n","\n","    def __init__(self, bert, embed_dim, hidden_dim, drop_prob, n_layers, out_dim):\n","      \n","      super(BERT_Arch, self).__init__()\n","\n","      self.bert = bert \n","      self.bilstm = nn.LSTM(embed_dim, hidden_dim, n_layers,dropout=drop_prob,  bidirectional=True, batch_first=True)\n","      self.dropout = nn.Dropout(drop_prob)\n","      self.fc1 = nn.Linear(2*hidden_dim,256)\n","      self.r1=nn.Tanh()\n","      self.fc2 = nn.Linear(256,out_dim)\n","      self.sf = nn.Sigmoid()\n","\n","    #define the forward pass\n","    def forward(self, sent_id, mask):\n","\n","      #pass the inputs to the model  \n","      embed, cls_hs = self.bert(sent_id, attention_mask=mask)\n","      x,_ = self.bilstm(embed)\n","      x = self.dropout(x)\n","      x = self.fc1(x)\n","      x = self.r1(x)\n","      x = self.fc2(x)\n","      x = self.sf(x)\n","\n","      return x\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S3XKHMRh_Nv8"},"source":["device = torch.device(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AIBiuMVN_Qjb","outputId":"b1eb2c06-0190-40c8-9c32-0e5b2886cdd7"},"source":["bert_model = BERT_Arch(model, 768, 256, 0.5, 1,1)\n","bert_model = bert_model.to(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n","  \"num_layers={}\".format(dropout, num_layers))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Ppg7Xka7_SsZ"},"source":["def weighted_binary_cross_entropy(output, target, weights=None):\n","    output = torch.clamp(output,min=1e-8,max=1-1e-8)\n","\n","    if weights is not None:\n","        assert len(weights) == 2\n","        loss = weights[1] * (target * torch.log(output)) + \\\n","               weights[0] * ((1 - target) * torch.log(1 - output))\n","    else:\n","        loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n","\n","    return torch.neg(torch.mean(loss))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IJVXK06J_W3D"},"source":["from transformers import AdamW\n","\n","#criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n","criterion=nn.BCELoss()\n","optimizer = AdamW(bert_model.parameters(), lr = 1e-3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIYhKOOG_Y2i"},"source":["bert_model=torch.load('/content/drive/My Drive/Model/count_t95_f70_ep20_sirdata.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g35IsxgW_d9O","outputId":"b536b0c6-ee15-467c-9d74-b5d801b9c4dd"},"source":["print(bert_model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["BERT_Arch(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (bilstm): LSTM(768, 256, batch_first=True, dropout=0.5, bidirectional=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc1): Linear(in_features=512, out_features=256, bias=True)\n","  (r1): Tanh()\n","  (fc2): Linear(in_features=256, out_features=1, bias=True)\n","  (sf): Sigmoid()\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lpRjQnp0A00S"},"source":["count_total=0\n","count_pred=0\n","meas_total=0\n","meas_pred=0\n","remain_total=0\n","remain_pred=0\n","for seq, mask, y in val_loader:\n","    bert_model.zero_grad()\n","    bert_model.eval()\n","    y_pred = bert_model(seq.to(device), mask.to(device))\n","    #y_pred = torch.transpose(y_pred, 2,1)\n","    #y = torch.transpose(y, 2,1)\n","    \n","    #_, target = y.max(dim=1)\n","    #_, predicted=y_pred.max(dim=1)\n","    target = y.cpu().data.numpy()\n","    predicted = y_pred.cpu().data.numpy()\n","    \n","    # print(target.shape,predicted.shape)\n","    for i in range(len(target)):\n","      for j in range(len(target[i])):\n","        if(target[i][j]==0):\n","          if(target[i][j]==predicted[i][j]):\n","            remain_pred+=1\n","          remain_total+=1\n","\n","        elif(target[i][j]==1):\n","          if(target[i][j]==predicted[i][j]):\n","            count_pred+=1\n","          count_total+=1\n","\n","        elif(target[i][j]==2):\n","          if(target[i][j]==predicted[i][j]):\n","            meas_pred+=1\n","          meas_total+=1\n","\n","\n","\n","    # for i in range(np_out.shape[0]):\n","    #   for j in range(np_out.shape[1]):\n","    #     for k in range(np_out.shape[2]):\n","    #       if np_out[i][j][k]>=0.2:\n","    #         np_out[i][j][k]=1\n","    #       else:\n","    #         np_out[i][j][k]=0\n","    \n","    \n","    #print(np.where(np_out==1))\n","    #print(\"##########\")\n","    #print(np.where(np_act==1))\n","\n","    # for i in range(np_out.shape[0]):\n","    #   for j in range(np_out.shape[1]):\n","    #     if np.max(np_out[i,j,:])==1 or np.max(np_act[i,j,:])==1:\n","    #       if np.max(np_out[i,j,:])==1 and np.max(np_act[i,j,:])==1:\n","    #         pos = pos + 1\n","    #       else:\n","    #         neg = neg + 1\n","\n","    # /for i in range(np_out.shape[0]):\n","    #  for j in range(np_out.shape[1]):\n","    #    for k in range(np_out.shape[2]):\n","    #      if (np_out[i,j,k])==1 or (np_act[i,j,k])==1:\n","    #        if (np_out[i,j,k])==1 and (np_act[i,j,k])==1:\n","    #          pos = pos + 1\n","    #        else:\n","    #          neg = neg + 1\n","\n","# print(pos/(pos+neg))\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eu1-VpaDBJg4","outputId":"df6ca7b6-673b-453b-b223-dd51f492b265"},"source":["print(meas_pred,meas_total)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"SVJSl4-jBMbH","outputId":"24589640-b3da-4db1-b2ac-5f68b7986657"},"source":["import matplotlib.pyplot as plt\n","best_threshold=[]\n","for k in range(1):\n","  m=0\n","  best_t=0\n","  prec_num = 0 \n","  prec_den = 0\n","  rec_num = 0\n","  rec_den = 0 \n","  threshold = np.linspace(0.1,0.99,10)\n","  f1 = []\n","  pre = []\n","  rec = []\n","  for t in threshold:\n","    for seq, mask, y in val_loader:\n","      bert_model.zero_grad()\n","      bert_model.eval()\n","      y_pred = bert_model(seq.to(device), mask.to(device))\n","      np_out = y_pred.cpu().data.numpy()\n","      np_act = y.cpu().data.numpy()\n","      #print(np_out)\n","    \n","      for i in range(np_out.shape[0]):\n","        for j in range(np_out.shape[1]):\n","        \n","          if np_out[i][j][k]>=t:\n","            np_out[i][j][k]=1\n","          else:\n","            np_out[i][j][k]=0\n","\n","      for i in range(np_out.shape[0]):\n","        for j in range(np_out.shape[1]):\n","          if np_out[i,j,k]==1:\n","            if np_out[i,j,k]==np_act[i,j,k]:\n","              prec_num = prec_num + 1\n","            else:\n","              prec_den = prec_den + 1\n","          if np_act[i,j,k]==1:\n","            if np_out[i,j,k]==np_act[i,j,k]:\n","              rec_num = rec_num + 1\n","            else:\n","              rec_den = rec_den + 1\n","\n","    precision = prec_num/(prec_num+prec_den)\n","    recall = rec_num/(rec_num+rec_den)\n","    F1 = 2*precision*recall/(precision+recall)\n","    f1.append(F1)\n","    pre.append(precision)\n","    rec.append(recall)\n","    if F1>m:\n","      best_t = t\n","    m = max(m,F1)\n","  best_threshold.append(best_t)\n","  plt.plot(threshold,pre)\n","  plt.plot(threshold,rec)\n","  plt.plot(threshold,f1)\n","  plt.show()\n","print(best_threshold)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["[0.99]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4bmPXFyJBTqx","outputId":"b7484c74-10fc-46bd-85e3-dcc43fc7aaad"},"source":["p=0\n","n=0\n","pos=0\n","neg=0\n","prec_num = 0 \n","prec_den = 0\n","rec_num = 0\n","rec_den = 0 \n","p1 = 0\n","n1=0\n","for seq, mask, y in val_loader:\n","    bert_model.zero_grad()\n","    bert_model.eval()\n","    y_pred = bert_model(seq.to(device), mask.to(device))\n","    np_out = y_pred.cpu().data.numpy()\n","    np_act = y.cpu().data.numpy()\n","    \n","    \n","    for i in range(np_out.shape[0]):\n","      for j in range(np_out.shape[1]):\n","        for k in range(np_out.shape[2]):\n","          if np_out[i][j][k]>=0.95:\n","            np_out[i][j][k]=1\n","          else:\n","            np_out[i][j][k]=0\n","\n","    for i in range(np_out.shape[0]):\n","      for j in range(np_out.shape[1]):\n","        if np.max(np_out[i,j,:])==1 or np.max(np_act[i,j,:])==1:\n","          if np.max(np_out[i,j,:])==1 and np.max(np_act[i,j,:])==1:\n","            p1 = p1 + 1\n","          else:\n","            n1 = n1 + 1\n","\n","    for i in range(np_out.shape[0]):\n","      for j in range(np_out.shape[1]):\n","        for k in range(np_out.shape[2]):\n","          if np_out[i,j,k] == np_act[i,j,k]:\n","            p = p +1\n","          else:\n","            n=n+1\n","          if (np_out[i,j,k])==1 or (np_act[i,j,k])==1:\n","            if (np_out[i,j,k])==1 and (np_act[i,j,k])==1:\n","              pos = pos + 1\n","            else:\n","              neg = neg + 1\n","          if np_out[i,j,k]==1:\n","            if np_out[i,j,k]==np_act[i,j,k]:\n","              prec_num = prec_num + 1\n","            else:\n","              prec_den = prec_den + 1\n","          if np_act[i,j,k]==1:\n","            if np_out[i,j,k]==np_act[i,j,k]:\n","              rec_num = rec_num + 1\n","            else:\n","              rec_den = rec_den + 1\n","\n","precision = prec_num/(prec_num+prec_den)\n","recall = rec_num/(rec_num+rec_den)\n","F1 = 2*precision*recall/(precision+recall)\n","\n","print(\"Entity recognition modified accuracy:-\" + str(p1/(p1+n1)))\n","print(\"--------COUNT RESULTS--------\")\n","print(\"Accuracy:-\" + str(p/(n+p)))\n","print(\"Modified Accuracy:-\" + str(pos/(pos+neg)))\n","print(\"Precision:-\" + str(precision))\n","print(\"Recall:-\" + str(recall))\n","print(\"F1 score:-\"+str(F1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Entity recognition modified accuracy:-0.5333333333333333\n","--------COUNT RESULTS--------\n","Accuracy:-0.9999312971105527\n","Modified Accuracy:-0.5333333333333333\n","Precision:-0.6666666666666666\n","Recall:-0.7272727272727273\n","F1 score:-0.6956521739130435\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V1W5zjR4Baeh"},"source":["s = \"I have 2 in my pocket, which are 99% pure\"\n","tokenized_text = tokenizer.tokenize(s)\n","test_inputs = tokenizer(s,max_length = 512,padding='max_length',truncation=True, return_tensors=\"pt\")\n","model.eval()\n","temp = bert_model(test_inputs['input_ids'].to(device), test_inputs['attention_mask'].to(device))>=0.95"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ujy-eypLB6wR"},"source":["idx2labels = {0: \"Count\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxqUGOyjB1cD","outputId":"c5b67cc1-9d44-4aa4-a532-32f36173239c"},"source":["for i in range(len(tokenized_text)):\n","  print(tokenized_text[i] + \": \", end='')\n","  for j in range(1):\n","    if(temp[0][i+1][j]):\n","      print(idx2labels[j] + \" \", end='')\n","  print()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["i: \n","have: \n","2: Count \n","in: \n","my: \n","pocket: \n",",: \n","which: \n","are: \n","99: \n","%: \n","pure: \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VvlFVQYNB3dl"},"source":[""],"execution_count":null,"outputs":[]}]}